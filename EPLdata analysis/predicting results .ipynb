{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epl_matches_train = pd.read_csv('epl_matches_train.csv')\n",
    "epl_matches_test = pd.read_csv('epl_matches_test.csv')\n",
    "epl_players = pd.read_csv('epl_players.csv')\n",
    "epl_teams = pd.read_csv('epl_teams.csv')\n",
    "epl_goals = pd.read_csv('epl_goals.csv')\n",
    "epl_potential_shots = pd.read_csv('epl_potential_shots.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>stage</th>\n",
       "      <th>date</th>\n",
       "      <th>match_id</th>\n",
       "      <th>home_team_id</th>\n",
       "      <th>away_team_id</th>\n",
       "      <th>home_player_X1</th>\n",
       "      <th>home_player_X2</th>\n",
       "      <th>home_player_X3</th>\n",
       "      <th>home_player_X4</th>\n",
       "      <th>...</th>\n",
       "      <th>red_card_home_team</th>\n",
       "      <th>red_card_away_team</th>\n",
       "      <th>crosses_home_team</th>\n",
       "      <th>crosses_away_team</th>\n",
       "      <th>corner_home_team</th>\n",
       "      <th>corner_away_team</th>\n",
       "      <th>possession_home_team</th>\n",
       "      <th>possession_away_team</th>\n",
       "      <th>home_team_goal</th>\n",
       "      <th>away_team_goal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-08-17 00:00:00</td>\n",
       "      <td>49337</td>\n",
       "      <td>10260</td>\n",
       "      <td>10261</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>55.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-08-16 00:00:00</td>\n",
       "      <td>38136</td>\n",
       "      <td>9825</td>\n",
       "      <td>8659</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>66.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-08-16 00:00:00</td>\n",
       "      <td>43276</td>\n",
       "      <td>8472</td>\n",
       "      <td>8650</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>46.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-08-16 00:00:00</td>\n",
       "      <td>40671</td>\n",
       "      <td>8654</td>\n",
       "      <td>8528</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>52.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-08-17 00:00:00</td>\n",
       "      <td>34633</td>\n",
       "      <td>10252</td>\n",
       "      <td>8456</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>52.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>2014/2015</td>\n",
       "      <td>9</td>\n",
       "      <td>2014-10-25 00:00:00</td>\n",
       "      <td>48955</td>\n",
       "      <td>8472</td>\n",
       "      <td>9825</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>39.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>2014/2015</td>\n",
       "      <td>9</td>\n",
       "      <td>2014-10-25 00:00:00</td>\n",
       "      <td>38293</td>\n",
       "      <td>10003</td>\n",
       "      <td>8197</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>49.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>2014/2015</td>\n",
       "      <td>9</td>\n",
       "      <td>2014-10-26 00:00:00</td>\n",
       "      <td>40230</td>\n",
       "      <td>8586</td>\n",
       "      <td>10261</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>68.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>2014/2015</td>\n",
       "      <td>9</td>\n",
       "      <td>2014-10-25 00:00:00</td>\n",
       "      <td>45930</td>\n",
       "      <td>8659</td>\n",
       "      <td>9826</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>69.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>2014/2015</td>\n",
       "      <td>9</td>\n",
       "      <td>2014-10-25 00:00:00</td>\n",
       "      <td>59737</td>\n",
       "      <td>8654</td>\n",
       "      <td>8456</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>31.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2660 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         season  stage                 date  match_id  home_team_id  \\\n",
       "0     2008/2009      1  2008-08-17 00:00:00     49337         10260   \n",
       "1     2008/2009      1  2008-08-16 00:00:00     38136          9825   \n",
       "2     2008/2009      1  2008-08-16 00:00:00     43276          8472   \n",
       "3     2008/2009      1  2008-08-16 00:00:00     40671          8654   \n",
       "4     2008/2009      1  2008-08-17 00:00:00     34633         10252   \n",
       "...         ...    ...                  ...       ...           ...   \n",
       "2655  2014/2015      9  2014-10-25 00:00:00     48955          8472   \n",
       "2656  2014/2015      9  2014-10-25 00:00:00     38293         10003   \n",
       "2657  2014/2015      9  2014-10-26 00:00:00     40230          8586   \n",
       "2658  2014/2015      9  2014-10-25 00:00:00     45930          8659   \n",
       "2659  2014/2015      9  2014-10-25 00:00:00     59737          8654   \n",
       "\n",
       "      away_team_id  home_player_X1  home_player_X2  home_player_X3  \\\n",
       "0            10261               1               2               4   \n",
       "1             8659               1               2               4   \n",
       "2             8650               1               2               4   \n",
       "3             8528               1               2               4   \n",
       "4             8456               1               2               4   \n",
       "...            ...             ...             ...             ...   \n",
       "2655          9825               1               2               4   \n",
       "2656          8197               1               2               4   \n",
       "2657         10261               1               2               4   \n",
       "2658          9826               1               2               4   \n",
       "2659          8456               1               2               4   \n",
       "\n",
       "      home_player_X4  ...  red_card_home_team  red_card_away_team  \\\n",
       "0                  6  ...                   0                   0   \n",
       "1                  6  ...                   0                   0   \n",
       "2                  6  ...                   0                   0   \n",
       "3                  6  ...                   0                   0   \n",
       "4                  6  ...                   0                   0   \n",
       "...              ...  ...                 ...                 ...   \n",
       "2655               6  ...                   0                   0   \n",
       "2656               6  ...                   0                   0   \n",
       "2657               6  ...                   0                   0   \n",
       "2658               6  ...                   0                   0   \n",
       "2659               6  ...                   0                   0   \n",
       "\n",
       "      crosses_home_team  crosses_away_team  corner_home_team  \\\n",
       "0                    24                  9                 6   \n",
       "1                    21                  7                 7   \n",
       "2                    15                 19                 1   \n",
       "3                    15                 27                 6   \n",
       "4                    16                 16                 7   \n",
       "...                 ...                ...               ...   \n",
       "2655                 14                 21                 3   \n",
       "2656                 10                 10                 2   \n",
       "2657                 29                 11                10   \n",
       "2658                 27                  7                 6   \n",
       "2659                 26                 17                 4   \n",
       "\n",
       "      corner_away_team  possession_home_team  possession_away_team  \\\n",
       "0                    6                  55.0                  45.0   \n",
       "1                    5                  66.0                  34.0   \n",
       "2                    8                  46.0                  54.0   \n",
       "3                   10                  52.0                  48.0   \n",
       "4                    8                  52.0                  48.0   \n",
       "...                ...                   ...                   ...   \n",
       "2655                 3                  39.0                  61.0   \n",
       "2656                 2                  49.0                  51.0   \n",
       "2657                 2                  68.0                  32.0   \n",
       "2658                 3                  69.0                  31.0   \n",
       "2659                 8                  31.0                  69.0   \n",
       "\n",
       "      home_team_goal  away_team_goal  \n",
       "0                  1               1  \n",
       "1                  1               0  \n",
       "2                  0               1  \n",
       "3                  2               1  \n",
       "4                  4               2  \n",
       "...              ...             ...  \n",
       "2655               0               2  \n",
       "2656               2               0  \n",
       "2657               1               2  \n",
       "2658               2               2  \n",
       "2659               2               1  \n",
       "\n",
       "[2660 rows x 90 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epl_matches_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>stage</th>\n",
       "      <th>date</th>\n",
       "      <th>match_id</th>\n",
       "      <th>home_team_id</th>\n",
       "      <th>away_team_id</th>\n",
       "      <th>home_player_X1</th>\n",
       "      <th>home_player_X2</th>\n",
       "      <th>home_player_X3</th>\n",
       "      <th>home_player_X4</th>\n",
       "      <th>...</th>\n",
       "      <th>away_player_2</th>\n",
       "      <th>away_player_3</th>\n",
       "      <th>away_player_4</th>\n",
       "      <th>away_player_5</th>\n",
       "      <th>away_player_6</th>\n",
       "      <th>away_player_7</th>\n",
       "      <th>away_player_8</th>\n",
       "      <th>away_player_9</th>\n",
       "      <th>away_player_10</th>\n",
       "      <th>away_player_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>8/9/2015 0:00</td>\n",
       "      <td>48994</td>\n",
       "      <td>9825</td>\n",
       "      <td>8654</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>109897.0</td>\n",
       "      <td>35110</td>\n",
       "      <td>49543</td>\n",
       "      <td>155782</td>\n",
       "      <td>37169</td>\n",
       "      <td>575789</td>\n",
       "      <td>148302</td>\n",
       "      <td>25496</td>\n",
       "      <td>18506</td>\n",
       "      <td>192899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>8/8/2015 0:00</td>\n",
       "      <td>54777</td>\n",
       "      <td>8678</td>\n",
       "      <td>10252</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>183500.0</td>\n",
       "      <td>24208</td>\n",
       "      <td>161414</td>\n",
       "      <td>473853</td>\n",
       "      <td>261313</td>\n",
       "      <td>179410</td>\n",
       "      <td>182223</td>\n",
       "      <td>23991</td>\n",
       "      <td>154280</td>\n",
       "      <td>23264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>8/8/2015 0:00</td>\n",
       "      <td>31434</td>\n",
       "      <td>8455</td>\n",
       "      <td>10003</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>111800.0</td>\n",
       "      <td>155050</td>\n",
       "      <td>24948</td>\n",
       "      <td>102356</td>\n",
       "      <td>127130</td>\n",
       "      <td>144996</td>\n",
       "      <td>95955</td>\n",
       "      <td>157729</td>\n",
       "      <td>52563</td>\n",
       "      <td>26344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>8/8/2015 0:00</td>\n",
       "      <td>56248</td>\n",
       "      <td>8668</td>\n",
       "      <td>9817</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>213809.0</td>\n",
       "      <td>41927</td>\n",
       "      <td>40548</td>\n",
       "      <td>35712</td>\n",
       "      <td>41365</td>\n",
       "      <td>30966</td>\n",
       "      <td>24915</td>\n",
       "      <td>37411</td>\n",
       "      <td>71724</td>\n",
       "      <td>72436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>8/8/2015 0:00</td>\n",
       "      <td>44311</td>\n",
       "      <td>8197</td>\n",
       "      <td>8472</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>22964.0</td>\n",
       "      <td>26108</td>\n",
       "      <td>165526</td>\n",
       "      <td>180330</td>\n",
       "      <td>35443</td>\n",
       "      <td>25150</td>\n",
       "      <td>109058</td>\n",
       "      <td>24159</td>\n",
       "      <td>30348</td>\n",
       "      <td>42598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2015/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>10/17/2015 0:00</td>\n",
       "      <td>42896</td>\n",
       "      <td>8466</td>\n",
       "      <td>8197</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>49571.0</td>\n",
       "      <td>23571</td>\n",
       "      <td>38899</td>\n",
       "      <td>43061</td>\n",
       "      <td>139671</td>\n",
       "      <td>173317</td>\n",
       "      <td>319300</td>\n",
       "      <td>214570</td>\n",
       "      <td>20694</td>\n",
       "      <td>286119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2015/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>10/19/2015 0:00</td>\n",
       "      <td>49098</td>\n",
       "      <td>10003</td>\n",
       "      <td>10194</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>34036.0</td>\n",
       "      <td>119541</td>\n",
       "      <td>200962</td>\n",
       "      <td>37194</td>\n",
       "      <td>23253</td>\n",
       "      <td>39109</td>\n",
       "      <td>176300</td>\n",
       "      <td>96643</td>\n",
       "      <td>110148</td>\n",
       "      <td>172321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>2015/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>10/17/2015 0:00</td>\n",
       "      <td>55212</td>\n",
       "      <td>8586</td>\n",
       "      <td>8650</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>157838.0</td>\n",
       "      <td>22764</td>\n",
       "      <td>94043</td>\n",
       "      <td>314605</td>\n",
       "      <td>95327</td>\n",
       "      <td>307021</td>\n",
       "      <td>38807</td>\n",
       "      <td>184536</td>\n",
       "      <td>37234</td>\n",
       "      <td>426202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>2015/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>10/17/2015 0:00</td>\n",
       "      <td>54075</td>\n",
       "      <td>9817</td>\n",
       "      <td>9825</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>427438.0</td>\n",
       "      <td>35606</td>\n",
       "      <td>46539</td>\n",
       "      <td>38521</td>\n",
       "      <td>159594</td>\n",
       "      <td>37436</td>\n",
       "      <td>75489</td>\n",
       "      <td>36378</td>\n",
       "      <td>50047</td>\n",
       "      <td>31013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>2015/2016</td>\n",
       "      <td>9</td>\n",
       "      <td>10/17/2015 0:00</td>\n",
       "      <td>40908</td>\n",
       "      <td>8659</td>\n",
       "      <td>8472</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>432040.0</td>\n",
       "      <td>24150</td>\n",
       "      <td>26108</td>\n",
       "      <td>22964</td>\n",
       "      <td>109330</td>\n",
       "      <td>25150</td>\n",
       "      <td>118929</td>\n",
       "      <td>35443</td>\n",
       "      <td>32627</td>\n",
       "      <td>184822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        season  stage             date  match_id  home_team_id  away_team_id  \\\n",
       "0    2015/2016      1    8/9/2015 0:00     48994          9825          8654   \n",
       "1    2015/2016      1    8/8/2015 0:00     54777          8678         10252   \n",
       "2    2015/2016      1    8/8/2015 0:00     31434          8455         10003   \n",
       "3    2015/2016      1    8/8/2015 0:00     56248          8668          9817   \n",
       "4    2015/2016      1    8/8/2015 0:00     44311          8197          8472   \n",
       "..         ...    ...              ...       ...           ...           ...   \n",
       "375  2015/2016      9  10/17/2015 0:00     42896          8466          8197   \n",
       "376  2015/2016      9  10/19/2015 0:00     49098         10003         10194   \n",
       "377  2015/2016      9  10/17/2015 0:00     55212          8586          8650   \n",
       "378  2015/2016      9  10/17/2015 0:00     54075          9817          9825   \n",
       "379  2015/2016      9  10/17/2015 0:00     40908          8659          8472   \n",
       "\n",
       "     home_player_X1  home_player_X2  home_player_X3  home_player_X4  ...  \\\n",
       "0                 1               2               4               6  ...   \n",
       "1                 1               2               4               6  ...   \n",
       "2                 1               2               4               6  ...   \n",
       "3                 1               2               4               6  ...   \n",
       "4                 1               3               5               7  ...   \n",
       "..              ...             ...             ...             ...  ...   \n",
       "375               1               2               4               6  ...   \n",
       "376               1               2               4               6  ...   \n",
       "377               1               2               4               6  ...   \n",
       "378               1               2               4               6  ...   \n",
       "379               1               2               4               6  ...   \n",
       "\n",
       "     away_player_2  away_player_3  away_player_4  away_player_5  \\\n",
       "0         109897.0          35110          49543         155782   \n",
       "1         183500.0          24208         161414         473853   \n",
       "2         111800.0         155050          24948         102356   \n",
       "3         213809.0          41927          40548          35712   \n",
       "4          22964.0          26108         165526         180330   \n",
       "..             ...            ...            ...            ...   \n",
       "375        49571.0          23571          38899          43061   \n",
       "376        34036.0         119541         200962          37194   \n",
       "377       157838.0          22764          94043         314605   \n",
       "378       427438.0          35606          46539          38521   \n",
       "379       432040.0          24150          26108          22964   \n",
       "\n",
       "     away_player_6  away_player_7  away_player_8  away_player_9  \\\n",
       "0            37169         575789         148302          25496   \n",
       "1           261313         179410         182223          23991   \n",
       "2           127130         144996          95955         157729   \n",
       "3            41365          30966          24915          37411   \n",
       "4            35443          25150         109058          24159   \n",
       "..             ...            ...            ...            ...   \n",
       "375         139671         173317         319300         214570   \n",
       "376          23253          39109         176300          96643   \n",
       "377          95327         307021          38807         184536   \n",
       "378         159594          37436          75489          36378   \n",
       "379         109330          25150         118929          35443   \n",
       "\n",
       "     away_player_10  away_player_11  \n",
       "0             18506          192899  \n",
       "1            154280           23264  \n",
       "2             52563           26344  \n",
       "3             71724           72436  \n",
       "4             30348           42598  \n",
       "..              ...             ...  \n",
       "375           20694          286119  \n",
       "376          110148          172321  \n",
       "377           37234          426202  \n",
       "378           50047           31013  \n",
       "379           32627          184822  \n",
       "\n",
       "[380 rows x 72 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epl_matches_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gen_result(df):\n",
    "    l = []\n",
    "    f= lambda x,y: 2 if x>y else (1 if x==y else 0)\n",
    "    home_goals = list(df.home_team_goal)\n",
    "    away_goals = list(df.away_team_goal)\n",
    "    m = len(home_goals)\n",
    "    for i in range(m):\n",
    "        l.append(f(home_goals[i],away_goals[i]))\n",
    "    df['results'] = l\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>stage</th>\n",
       "      <th>date</th>\n",
       "      <th>match_id</th>\n",
       "      <th>home_team_id</th>\n",
       "      <th>away_team_id</th>\n",
       "      <th>home_player_X1</th>\n",
       "      <th>home_player_X2</th>\n",
       "      <th>home_player_X3</th>\n",
       "      <th>home_player_X4</th>\n",
       "      <th>home_player_X5</th>\n",
       "      <th>home_player_X6</th>\n",
       "      <th>home_player_X7</th>\n",
       "      <th>home_player_X8</th>\n",
       "      <th>home_player_X9</th>\n",
       "      <th>home_player_X10</th>\n",
       "      <th>home_player_X11</th>\n",
       "      <th>away_player_X1</th>\n",
       "      <th>away_player_X2</th>\n",
       "      <th>away_player_X3</th>\n",
       "      <th>away_player_X4</th>\n",
       "      <th>away_player_X5</th>\n",
       "      <th>away_player_X6</th>\n",
       "      <th>away_player_X7</th>\n",
       "      <th>away_player_X8</th>\n",
       "      <th>away_player_X9</th>\n",
       "      <th>away_player_X10</th>\n",
       "      <th>away_player_X11</th>\n",
       "      <th>home_player_Y1</th>\n",
       "      <th>home_player_Y2</th>\n",
       "      <th>home_player_Y3</th>\n",
       "      <th>home_player_Y4</th>\n",
       "      <th>home_player_Y5</th>\n",
       "      <th>home_player_Y6</th>\n",
       "      <th>home_player_Y7</th>\n",
       "      <th>home_player_Y8</th>\n",
       "      <th>home_player_Y9</th>\n",
       "      <th>home_player_Y10</th>\n",
       "      <th>home_player_Y11</th>\n",
       "      <th>away_player_Y1</th>\n",
       "      <th>away_player_Y2</th>\n",
       "      <th>away_player_Y3</th>\n",
       "      <th>away_player_Y4</th>\n",
       "      <th>away_player_Y5</th>\n",
       "      <th>away_player_Y6</th>\n",
       "      <th>away_player_Y7</th>\n",
       "      <th>away_player_Y8</th>\n",
       "      <th>away_player_Y9</th>\n",
       "      <th>away_player_Y10</th>\n",
       "      <th>away_player_Y11</th>\n",
       "      <th>home_player_1</th>\n",
       "      <th>home_player_2</th>\n",
       "      <th>home_player_3</th>\n",
       "      <th>home_player_4</th>\n",
       "      <th>home_player_5</th>\n",
       "      <th>home_player_6</th>\n",
       "      <th>home_player_7</th>\n",
       "      <th>home_player_8</th>\n",
       "      <th>home_player_9</th>\n",
       "      <th>home_player_10</th>\n",
       "      <th>home_player_11</th>\n",
       "      <th>away_player_1</th>\n",
       "      <th>away_player_2</th>\n",
       "      <th>away_player_3</th>\n",
       "      <th>away_player_4</th>\n",
       "      <th>away_player_5</th>\n",
       "      <th>away_player_6</th>\n",
       "      <th>away_player_7</th>\n",
       "      <th>away_player_8</th>\n",
       "      <th>away_player_9</th>\n",
       "      <th>away_player_10</th>\n",
       "      <th>away_player_11</th>\n",
       "      <th>on_target_shot_home_team</th>\n",
       "      <th>on_target_shot_away_team</th>\n",
       "      <th>off_target_shot_home_team</th>\n",
       "      <th>off_target_shot_away_team</th>\n",
       "      <th>foul_home_team</th>\n",
       "      <th>foul_away_team</th>\n",
       "      <th>yellow_card_home_team</th>\n",
       "      <th>yellow_card_away_team</th>\n",
       "      <th>red_card_home_team</th>\n",
       "      <th>red_card_away_team</th>\n",
       "      <th>crosses_home_team</th>\n",
       "      <th>crosses_away_team</th>\n",
       "      <th>corner_home_team</th>\n",
       "      <th>corner_away_team</th>\n",
       "      <th>possession_home_team</th>\n",
       "      <th>possession_away_team</th>\n",
       "      <th>home_team_goal</th>\n",
       "      <th>away_team_goal</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-08-17 00:00:00</td>\n",
       "      <td>49337</td>\n",
       "      <td>10260</td>\n",
       "      <td>10261</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>30726</td>\n",
       "      <td>30362.0</td>\n",
       "      <td>30620</td>\n",
       "      <td>30865</td>\n",
       "      <td>32569.0</td>\n",
       "      <td>24148</td>\n",
       "      <td>34944.0</td>\n",
       "      <td>30373.0</td>\n",
       "      <td>24154.0</td>\n",
       "      <td>24157.0</td>\n",
       "      <td>30829.0</td>\n",
       "      <td>24224</td>\n",
       "      <td>25518.0</td>\n",
       "      <td>24228.0</td>\n",
       "      <td>30929</td>\n",
       "      <td>29581.0</td>\n",
       "      <td>38807.0</td>\n",
       "      <td>40565.0</td>\n",
       "      <td>30360.0</td>\n",
       "      <td>33852.0</td>\n",
       "      <td>34574.0</td>\n",
       "      <td>37799.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>55.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-08-16 00:00:00</td>\n",
       "      <td>38136</td>\n",
       "      <td>9825</td>\n",
       "      <td>8659</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>23686</td>\n",
       "      <td>26111.0</td>\n",
       "      <td>38835</td>\n",
       "      <td>30986</td>\n",
       "      <td>31291.0</td>\n",
       "      <td>31013</td>\n",
       "      <td>30935.0</td>\n",
       "      <td>39297.0</td>\n",
       "      <td>26181.0</td>\n",
       "      <td>30960.0</td>\n",
       "      <td>36410.0</td>\n",
       "      <td>36373</td>\n",
       "      <td>36832.0</td>\n",
       "      <td>23115.0</td>\n",
       "      <td>37280</td>\n",
       "      <td>24728.0</td>\n",
       "      <td>24664.0</td>\n",
       "      <td>31088.0</td>\n",
       "      <td>23257.0</td>\n",
       "      <td>24171.0</td>\n",
       "      <td>25922.0</td>\n",
       "      <td>27267.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>66.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-08-16 00:00:00</td>\n",
       "      <td>43276</td>\n",
       "      <td>8472</td>\n",
       "      <td>8650</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>32562</td>\n",
       "      <td>38836.0</td>\n",
       "      <td>24446</td>\n",
       "      <td>24408</td>\n",
       "      <td>36786.0</td>\n",
       "      <td>38802</td>\n",
       "      <td>24655.0</td>\n",
       "      <td>17866.0</td>\n",
       "      <td>30352.0</td>\n",
       "      <td>23927.0</td>\n",
       "      <td>24410.0</td>\n",
       "      <td>30660</td>\n",
       "      <td>37442.0</td>\n",
       "      <td>30617.0</td>\n",
       "      <td>24134</td>\n",
       "      <td>414792.0</td>\n",
       "      <td>37139.0</td>\n",
       "      <td>30618.0</td>\n",
       "      <td>40701.0</td>\n",
       "      <td>24800.0</td>\n",
       "      <td>24635.0</td>\n",
       "      <td>30853.0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>46.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-08-16 00:00:00</td>\n",
       "      <td>40671</td>\n",
       "      <td>8654</td>\n",
       "      <td>8528</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>36374</td>\n",
       "      <td>30966.0</td>\n",
       "      <td>23818</td>\n",
       "      <td>37277</td>\n",
       "      <td>30687.0</td>\n",
       "      <td>36394</td>\n",
       "      <td>37169.0</td>\n",
       "      <td>24223.0</td>\n",
       "      <td>24773.0</td>\n",
       "      <td>34543.0</td>\n",
       "      <td>23139.0</td>\n",
       "      <td>34421</td>\n",
       "      <td>34987.0</td>\n",
       "      <td>35472.0</td>\n",
       "      <td>111865</td>\n",
       "      <td>25005.0</td>\n",
       "      <td>35327.0</td>\n",
       "      <td>25150.0</td>\n",
       "      <td>97988.0</td>\n",
       "      <td>41877.0</td>\n",
       "      <td>127857.0</td>\n",
       "      <td>34466.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>52.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-08-17 00:00:00</td>\n",
       "      <td>34633</td>\n",
       "      <td>10252</td>\n",
       "      <td>8456</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>30380</td>\n",
       "      <td>30357.0</td>\n",
       "      <td>24658</td>\n",
       "      <td>43280</td>\n",
       "      <td>23282.0</td>\n",
       "      <td>38609</td>\n",
       "      <td>24780.0</td>\n",
       "      <td>23782.0</td>\n",
       "      <td>23354.0</td>\n",
       "      <td>23264.0</td>\n",
       "      <td>26165.0</td>\n",
       "      <td>31432</td>\n",
       "      <td>46403.0</td>\n",
       "      <td>24208.0</td>\n",
       "      <td>23939</td>\n",
       "      <td>33963.0</td>\n",
       "      <td>47413.0</td>\n",
       "      <td>40198.0</td>\n",
       "      <td>42119.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33633.0</td>\n",
       "      <td>107216.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>52.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>2014/2015</td>\n",
       "      <td>9</td>\n",
       "      <td>2014-10-25 00:00:00</td>\n",
       "      <td>48955</td>\n",
       "      <td>8472</td>\n",
       "      <td>9825</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>37233</td>\n",
       "      <td>188540.0</td>\n",
       "      <td>24150</td>\n",
       "      <td>30362</td>\n",
       "      <td>180330.0</td>\n",
       "      <td>25150</td>\n",
       "      <td>24159.0</td>\n",
       "      <td>35443.0</td>\n",
       "      <td>109058.0</td>\n",
       "      <td>114218.0</td>\n",
       "      <td>32627.0</td>\n",
       "      <td>169718</td>\n",
       "      <td>425255.0</td>\n",
       "      <td>35606.0</td>\n",
       "      <td>38521</td>\n",
       "      <td>78513.0</td>\n",
       "      <td>23688.0</td>\n",
       "      <td>24011.0</td>\n",
       "      <td>50047.0</td>\n",
       "      <td>37436.0</td>\n",
       "      <td>196386.0</td>\n",
       "      <td>113836.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>39.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>2014/2015</td>\n",
       "      <td>9</td>\n",
       "      <td>2014-10-25 00:00:00</td>\n",
       "      <td>38293</td>\n",
       "      <td>10003</td>\n",
       "      <td>8197</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>30973</td>\n",
       "      <td>89185.0</td>\n",
       "      <td>24948</td>\n",
       "      <td>155050</td>\n",
       "      <td>102356.0</td>\n",
       "      <td>144996</td>\n",
       "      <td>127130.0</td>\n",
       "      <td>52563.0</td>\n",
       "      <td>157729.0</td>\n",
       "      <td>38831.0</td>\n",
       "      <td>143365.0</td>\n",
       "      <td>37770</td>\n",
       "      <td>67850.0</td>\n",
       "      <td>23571.0</td>\n",
       "      <td>210804</td>\n",
       "      <td>24781.0</td>\n",
       "      <td>173317.0</td>\n",
       "      <td>22894.0</td>\n",
       "      <td>278343.0</td>\n",
       "      <td>23190.0</td>\n",
       "      <td>286119.0</td>\n",
       "      <td>26554.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>49.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>2014/2015</td>\n",
       "      <td>9</td>\n",
       "      <td>2014-10-26 00:00:00</td>\n",
       "      <td>40230</td>\n",
       "      <td>8586</td>\n",
       "      <td>10261</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>26295</td>\n",
       "      <td>361315.0</td>\n",
       "      <td>26108</td>\n",
       "      <td>37762</td>\n",
       "      <td>46353.0</td>\n",
       "      <td>41365</td>\n",
       "      <td>160448.0</td>\n",
       "      <td>174850.0</td>\n",
       "      <td>157723.0</td>\n",
       "      <td>110189.0</td>\n",
       "      <td>30960.0</td>\n",
       "      <td>24229</td>\n",
       "      <td>104482.0</td>\n",
       "      <td>24228.0</td>\n",
       "      <td>30929</td>\n",
       "      <td>308932.0</td>\n",
       "      <td>109652.0</td>\n",
       "      <td>160243.0</td>\n",
       "      <td>39968.0</td>\n",
       "      <td>94550.0</td>\n",
       "      <td>31292.0</td>\n",
       "      <td>479020.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>68.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>2014/2015</td>\n",
       "      <td>9</td>\n",
       "      <td>2014-10-25 00:00:00</td>\n",
       "      <td>45930</td>\n",
       "      <td>8659</td>\n",
       "      <td>9826</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>24147</td>\n",
       "      <td>265918.0</td>\n",
       "      <td>169162</td>\n",
       "      <td>33086</td>\n",
       "      <td>38795.0</td>\n",
       "      <td>24171</td>\n",
       "      <td>25075.0</td>\n",
       "      <td>32734.0</td>\n",
       "      <td>33468.0</td>\n",
       "      <td>23257.0</td>\n",
       "      <td>239807.0</td>\n",
       "      <td>22998</td>\n",
       "      <td>154271.0</td>\n",
       "      <td>26777.0</td>\n",
       "      <td>23358</td>\n",
       "      <td>146830.0</td>\n",
       "      <td>198510.0</td>\n",
       "      <td>8985.0</td>\n",
       "      <td>22929.0</td>\n",
       "      <td>160194.0</td>\n",
       "      <td>25537.0</td>\n",
       "      <td>24157.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>69.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>2014/2015</td>\n",
       "      <td>9</td>\n",
       "      <td>2014-10-25 00:00:00</td>\n",
       "      <td>59737</td>\n",
       "      <td>8654</td>\n",
       "      <td>8456</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>169756</td>\n",
       "      <td>214685.0</td>\n",
       "      <td>24751</td>\n",
       "      <td>35110</td>\n",
       "      <td>155782.0</td>\n",
       "      <td>23678</td>\n",
       "      <td>37169.0</td>\n",
       "      <td>41232.0</td>\n",
       "      <td>30892.0</td>\n",
       "      <td>192899.0</td>\n",
       "      <td>195927.0</td>\n",
       "      <td>31432</td>\n",
       "      <td>30509.0</td>\n",
       "      <td>39027.0</td>\n",
       "      <td>156551</td>\n",
       "      <td>31291.0</td>\n",
       "      <td>101103.0</td>\n",
       "      <td>36615.0</td>\n",
       "      <td>33991.0</td>\n",
       "      <td>37412.0</td>\n",
       "      <td>37459.0</td>\n",
       "      <td>15403.0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>31.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2660 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         season  stage                 date  match_id  home_team_id  \\\n",
       "0     2008/2009      1  2008-08-17 00:00:00     49337         10260   \n",
       "1     2008/2009      1  2008-08-16 00:00:00     38136          9825   \n",
       "2     2008/2009      1  2008-08-16 00:00:00     43276          8472   \n",
       "3     2008/2009      1  2008-08-16 00:00:00     40671          8654   \n",
       "4     2008/2009      1  2008-08-17 00:00:00     34633         10252   \n",
       "...         ...    ...                  ...       ...           ...   \n",
       "2655  2014/2015      9  2014-10-25 00:00:00     48955          8472   \n",
       "2656  2014/2015      9  2014-10-25 00:00:00     38293         10003   \n",
       "2657  2014/2015      9  2014-10-26 00:00:00     40230          8586   \n",
       "2658  2014/2015      9  2014-10-25 00:00:00     45930          8659   \n",
       "2659  2014/2015      9  2014-10-25 00:00:00     59737          8654   \n",
       "\n",
       "      away_team_id  home_player_X1  home_player_X2  home_player_X3  \\\n",
       "0            10261               1               2               4   \n",
       "1             8659               1               2               4   \n",
       "2             8650               1               2               4   \n",
       "3             8528               1               2               4   \n",
       "4             8456               1               2               4   \n",
       "...            ...             ...             ...             ...   \n",
       "2655          9825               1               2               4   \n",
       "2656          8197               1               2               4   \n",
       "2657         10261               1               2               4   \n",
       "2658          9826               1               2               4   \n",
       "2659          8456               1               2               4   \n",
       "\n",
       "      home_player_X4  home_player_X5  home_player_X6  home_player_X7  \\\n",
       "0                  6               8               2               4   \n",
       "1                  6               8               2               4   \n",
       "2                  6               8               2               4   \n",
       "3                  6               8               2               4   \n",
       "4                  6               8               2               4   \n",
       "...              ...             ...             ...             ...   \n",
       "2655               6               8               5               2   \n",
       "2656               6               8               4               6   \n",
       "2657               6               8               4               6   \n",
       "2658               6               8               4               6   \n",
       "2659               6               8               5               4   \n",
       "\n",
       "      home_player_X8  home_player_X9  home_player_X10  home_player_X11  \\\n",
       "0                  6               8                4                6   \n",
       "1                  6               8                4                6   \n",
       "2                  6               8                4                6   \n",
       "3                  6               8                4                6   \n",
       "4                  6               8                4                6   \n",
       "...              ...             ...              ...              ...   \n",
       "2655               4               6                8                5   \n",
       "2656               3               5                7                5   \n",
       "2657               3               5                7                5   \n",
       "2658               3               5                7                5   \n",
       "2659               6               5                4                6   \n",
       "\n",
       "      away_player_X1  away_player_X2  away_player_X3  away_player_X4  \\\n",
       "0                  1               2               4               6   \n",
       "1                  1               2               4               6   \n",
       "2                  1               2               4               6   \n",
       "3                  1               2               6               8   \n",
       "4                  1               2               4               6   \n",
       "...              ...             ...             ...             ...   \n",
       "2655               1               2               4               6   \n",
       "2656               1               2               4               6   \n",
       "2657               1               2               4               6   \n",
       "2658               1               2               4               6   \n",
       "2659               1               2               4               6   \n",
       "\n",
       "      away_player_X5  away_player_X6  away_player_X7  away_player_X8  \\\n",
       "0                  8               2               4               6   \n",
       "1                  8               5               7               9   \n",
       "2                  8               2               4               6   \n",
       "3                  4               2               4               6   \n",
       "4                  8               1               3               5   \n",
       "...              ...             ...             ...             ...   \n",
       "2655               8               4               6               3   \n",
       "2656               8               4               6               3   \n",
       "2657               8               4               6               3   \n",
       "2658               8               2               4               6   \n",
       "2659               8               4               6               3   \n",
       "\n",
       "      away_player_X9  away_player_X10  away_player_X11  home_player_Y1  \\\n",
       "0                  8                5                5               1   \n",
       "1                  1                3                5               1   \n",
       "2                  8                4                6               1   \n",
       "3                  8                4                6               1   \n",
       "4                  7                9                5               1   \n",
       "...              ...              ...              ...             ...   \n",
       "2655               5                7                5               1   \n",
       "2656               5                7                5               1   \n",
       "2657               5                7                5               1   \n",
       "2658               8                5                5               1   \n",
       "2659               5                7                5               1   \n",
       "\n",
       "      home_player_Y2  home_player_Y3  home_player_Y4  home_player_Y5  \\\n",
       "0                  3               3               3               3   \n",
       "1                  3               3               3               3   \n",
       "2                  3               3               3               3   \n",
       "3                  3               3               3               3   \n",
       "4                  3               3               3               3   \n",
       "...              ...             ...             ...             ...   \n",
       "2655               3               3               3               3   \n",
       "2656               3               3               3               3   \n",
       "2657               3               3               3               3   \n",
       "2658               3               3               3               3   \n",
       "2659               3               3               3               3   \n",
       "\n",
       "      home_player_Y6  home_player_Y7  home_player_Y8  home_player_Y9  \\\n",
       "0                  7               7               7               7   \n",
       "1                  7               7               7               7   \n",
       "2                  7               7               7               7   \n",
       "3                  7               7               7               7   \n",
       "4                  7               7               7               7   \n",
       "...              ...             ...             ...             ...   \n",
       "2655               6               8               8               8   \n",
       "2656               6               6               8               8   \n",
       "2657               6               6               8               8   \n",
       "2658               6               6               8               8   \n",
       "2659               6               7               7               9   \n",
       "\n",
       "      home_player_Y10  home_player_Y11  away_player_Y1  away_player_Y2  \\\n",
       "0                  10               10               1               3   \n",
       "1                  10               10               1               3   \n",
       "2                  10               10               1               3   \n",
       "3                  10               10               1               3   \n",
       "4                  10               10               1               3   \n",
       "...               ...              ...             ...             ...   \n",
       "2655                8               11               1               3   \n",
       "2656                8               11               1               3   \n",
       "2657                8               11               1               3   \n",
       "2658                8               11               1               3   \n",
       "2659               11               11               1               3   \n",
       "\n",
       "      away_player_Y3  away_player_Y4  away_player_Y5  away_player_Y6  \\\n",
       "0                  3               3               3               7   \n",
       "1                  3               3               3               7   \n",
       "2                  3               3               3               7   \n",
       "3                  3               3               3               7   \n",
       "4                  3               3               3               7   \n",
       "...              ...             ...             ...             ...   \n",
       "2655               3               3               3               6   \n",
       "2656               3               3               3               6   \n",
       "2657               3               3               3               6   \n",
       "2658               3               3               3               7   \n",
       "2659               3               3               3               6   \n",
       "\n",
       "      away_player_Y7  away_player_Y8  away_player_Y9  away_player_Y10  \\\n",
       "0                  7               7               7                9   \n",
       "1                  7               7               7                7   \n",
       "2                  7               7               7               10   \n",
       "3                  7               7               7               10   \n",
       "4                  7               7               7                7   \n",
       "...              ...             ...             ...              ...   \n",
       "2655               6               8               8                8   \n",
       "2656               6               8               8                8   \n",
       "2657               6               8               8                8   \n",
       "2658               7               7               7                9   \n",
       "2659               6               8               8                8   \n",
       "\n",
       "      away_player_Y11  home_player_1  home_player_2  home_player_3  \\\n",
       "0                  11          30726        30362.0          30620   \n",
       "1                  11          23686        26111.0          38835   \n",
       "2                  10          32562        38836.0          24446   \n",
       "3                  10          36374        30966.0          23818   \n",
       "4                  11          30380        30357.0          24658   \n",
       "...               ...            ...            ...            ...   \n",
       "2655               11          37233       188540.0          24150   \n",
       "2656               11          30973        89185.0          24948   \n",
       "2657               11          26295       361315.0          26108   \n",
       "2658               11          24147       265918.0         169162   \n",
       "2659               11         169756       214685.0          24751   \n",
       "\n",
       "      home_player_4  home_player_5  home_player_6  home_player_7  \\\n",
       "0             30865        32569.0          24148        34944.0   \n",
       "1             30986        31291.0          31013        30935.0   \n",
       "2             24408        36786.0          38802        24655.0   \n",
       "3             37277        30687.0          36394        37169.0   \n",
       "4             43280        23282.0          38609        24780.0   \n",
       "...             ...            ...            ...            ...   \n",
       "2655          30362       180330.0          25150        24159.0   \n",
       "2656         155050       102356.0         144996       127130.0   \n",
       "2657          37762        46353.0          41365       160448.0   \n",
       "2658          33086        38795.0          24171        25075.0   \n",
       "2659          35110       155782.0          23678        37169.0   \n",
       "\n",
       "      home_player_8  home_player_9  home_player_10  home_player_11  \\\n",
       "0           30373.0        24154.0         24157.0         30829.0   \n",
       "1           39297.0        26181.0         30960.0         36410.0   \n",
       "2           17866.0        30352.0         23927.0         24410.0   \n",
       "3           24223.0        24773.0         34543.0         23139.0   \n",
       "4           23782.0        23354.0         23264.0         26165.0   \n",
       "...             ...            ...             ...             ...   \n",
       "2655        35443.0       109058.0        114218.0         32627.0   \n",
       "2656        52563.0       157729.0         38831.0        143365.0   \n",
       "2657       174850.0       157723.0        110189.0         30960.0   \n",
       "2658        32734.0        33468.0         23257.0        239807.0   \n",
       "2659        41232.0        30892.0        192899.0        195927.0   \n",
       "\n",
       "      away_player_1  away_player_2  away_player_3  away_player_4  \\\n",
       "0             24224        25518.0        24228.0          30929   \n",
       "1             36373        36832.0        23115.0          37280   \n",
       "2             30660        37442.0        30617.0          24134   \n",
       "3             34421        34987.0        35472.0         111865   \n",
       "4             31432        46403.0        24208.0          23939   \n",
       "...             ...            ...            ...            ...   \n",
       "2655         169718       425255.0        35606.0          38521   \n",
       "2656          37770        67850.0        23571.0         210804   \n",
       "2657          24229       104482.0        24228.0          30929   \n",
       "2658          22998       154271.0        26777.0          23358   \n",
       "2659          31432        30509.0        39027.0         156551   \n",
       "\n",
       "      away_player_5  away_player_6  away_player_7  away_player_8  \\\n",
       "0           29581.0        38807.0        40565.0        30360.0   \n",
       "1           24728.0        24664.0        31088.0        23257.0   \n",
       "2          414792.0        37139.0        30618.0        40701.0   \n",
       "3           25005.0        35327.0        25150.0        97988.0   \n",
       "4           33963.0        47413.0        40198.0        42119.0   \n",
       "...             ...            ...            ...            ...   \n",
       "2655        78513.0        23688.0        24011.0        50047.0   \n",
       "2656        24781.0       173317.0        22894.0       278343.0   \n",
       "2657       308932.0       109652.0       160243.0        39968.0   \n",
       "2658       146830.0       198510.0         8985.0        22929.0   \n",
       "2659        31291.0       101103.0        36615.0        33991.0   \n",
       "\n",
       "      away_player_9  away_player_10  away_player_11  on_target_shot_home_team  \\\n",
       "0           33852.0         34574.0         37799.0                        11   \n",
       "1           24171.0         25922.0         27267.0                        12   \n",
       "2           24800.0         24635.0         30853.0                         4   \n",
       "3           41877.0        127857.0         34466.0                         5   \n",
       "4               NaN         33633.0        107216.0                         5   \n",
       "...             ...             ...             ...                       ...   \n",
       "2655        37436.0        196386.0        113836.0                         4   \n",
       "2656        23190.0        286119.0         26554.0                         2   \n",
       "2657        94550.0         31292.0        479020.0                         8   \n",
       "2658       160194.0         25537.0         24157.0                         7   \n",
       "2659        37412.0         37459.0         15403.0                         4   \n",
       "\n",
       "      on_target_shot_away_team  off_target_shot_home_team  \\\n",
       "0                            1                         10   \n",
       "1                            2                         13   \n",
       "2                           11                          3   \n",
       "3                            7                          7   \n",
       "4                            9                          4   \n",
       "...                        ...                        ...   \n",
       "2655                         5                          3   \n",
       "2656                         4                          5   \n",
       "2657                         2                          9   \n",
       "2658                         7                          8   \n",
       "2659                         9                          6   \n",
       "\n",
       "      off_target_shot_away_team  foul_home_team  foul_away_team  \\\n",
       "0                             9              16              11   \n",
       "1                             3              11               9   \n",
       "2                             5              13              12   \n",
       "3                            15              14              13   \n",
       "4                             5              11              13   \n",
       "...                         ...             ...             ...   \n",
       "2655                          9               9               8   \n",
       "2656                          4               7              11   \n",
       "2657                          4               9              12   \n",
       "2658                          2              14               8   \n",
       "2659                         13              12              14   \n",
       "\n",
       "      yellow_card_home_team  yellow_card_away_team  red_card_home_team  \\\n",
       "0                         3                      0                   0   \n",
       "1                         0                      0                   0   \n",
       "2                         0                      2                   0   \n",
       "3                         2                      1                   0   \n",
       "4                         0                      1                   0   \n",
       "...                     ...                    ...                 ...   \n",
       "2655                      3                      3                   0   \n",
       "2656                      0                      0                   0   \n",
       "2657                      2                      3                   0   \n",
       "2658                      3                      1                   0   \n",
       "2659                      2                      1                   0   \n",
       "\n",
       "      red_card_away_team  crosses_home_team  crosses_away_team  \\\n",
       "0                      0                 24                  9   \n",
       "1                      0                 21                  7   \n",
       "2                      0                 15                 19   \n",
       "3                      0                 15                 27   \n",
       "4                      0                 16                 16   \n",
       "...                  ...                ...                ...   \n",
       "2655                   0                 14                 21   \n",
       "2656                   0                 10                 10   \n",
       "2657                   0                 29                 11   \n",
       "2658                   0                 27                  7   \n",
       "2659                   0                 26                 17   \n",
       "\n",
       "      corner_home_team  corner_away_team  possession_home_team  \\\n",
       "0                    6                 6                  55.0   \n",
       "1                    7                 5                  66.0   \n",
       "2                    1                 8                  46.0   \n",
       "3                    6                10                  52.0   \n",
       "4                    7                 8                  52.0   \n",
       "...                ...               ...                   ...   \n",
       "2655                 3                 3                  39.0   \n",
       "2656                 2                 2                  49.0   \n",
       "2657                10                 2                  68.0   \n",
       "2658                 6                 3                  69.0   \n",
       "2659                 4                 8                  31.0   \n",
       "\n",
       "      possession_away_team  home_team_goal  away_team_goal  results  \n",
       "0                     45.0               1               1        1  \n",
       "1                     34.0               1               0        2  \n",
       "2                     54.0               0               1        0  \n",
       "3                     48.0               2               1        2  \n",
       "4                     48.0               4               2        2  \n",
       "...                    ...             ...             ...      ...  \n",
       "2655                  61.0               0               2        0  \n",
       "2656                  51.0               2               0        2  \n",
       "2657                  32.0               1               2        0  \n",
       "2658                  31.0               2               2        1  \n",
       "2659                  69.0               2               1        2  \n",
       "\n",
       "[2660 rows x 91 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epl_matches_train = gen_result(epl_matches_train)\n",
    "epl_matches_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_data = epl_teams.select_dtypes(include = ['int64','float64'])\n",
    "teams_data = teams_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_id</th>\n",
       "      <th>buildUpPlaySpeed</th>\n",
       "      <th>buildUpPlayDribbling</th>\n",
       "      <th>buildUpPlayPassing</th>\n",
       "      <th>chanceCreationPassing</th>\n",
       "      <th>chanceCreationCrossing</th>\n",
       "      <th>chanceCreationShooting</th>\n",
       "      <th>defencePressure</th>\n",
       "      <th>defenceAggression</th>\n",
       "      <th>defenceTeamWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9825</td>\n",
       "      <td>59</td>\n",
       "      <td>51.0</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>55</td>\n",
       "      <td>64</td>\n",
       "      <td>51</td>\n",
       "      <td>44</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9825</td>\n",
       "      <td>59</td>\n",
       "      <td>51.0</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>51</td>\n",
       "      <td>44</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10252</td>\n",
       "      <td>66</td>\n",
       "      <td>32.0</td>\n",
       "      <td>72</td>\n",
       "      <td>63</td>\n",
       "      <td>48</td>\n",
       "      <td>56</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10252</td>\n",
       "      <td>63</td>\n",
       "      <td>37.0</td>\n",
       "      <td>54</td>\n",
       "      <td>60</td>\n",
       "      <td>48</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "      <td>44</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8658</td>\n",
       "      <td>56</td>\n",
       "      <td>39.0</td>\n",
       "      <td>79</td>\n",
       "      <td>77</td>\n",
       "      <td>71</td>\n",
       "      <td>56</td>\n",
       "      <td>42</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>8654</td>\n",
       "      <td>77</td>\n",
       "      <td>37.0</td>\n",
       "      <td>57</td>\n",
       "      <td>68</td>\n",
       "      <td>73</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>8528</td>\n",
       "      <td>51</td>\n",
       "      <td>36.0</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>8528</td>\n",
       "      <td>51</td>\n",
       "      <td>37.0</td>\n",
       "      <td>56</td>\n",
       "      <td>52</td>\n",
       "      <td>59</td>\n",
       "      <td>40</td>\n",
       "      <td>62</td>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>8602</td>\n",
       "      <td>47</td>\n",
       "      <td>28.0</td>\n",
       "      <td>58</td>\n",
       "      <td>55</td>\n",
       "      <td>64</td>\n",
       "      <td>56</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>8602</td>\n",
       "      <td>46</td>\n",
       "      <td>36.0</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     team_id  buildUpPlaySpeed  buildUpPlayDribbling  buildUpPlayPassing  \\\n",
       "4       9825                59                  51.0                  26   \n",
       "5       9825                59                  51.0                  30   \n",
       "10     10252                66                  32.0                  72   \n",
       "11     10252                63                  37.0                  54   \n",
       "16      8658                56                  39.0                  79   \n",
       "..       ...               ...                   ...                 ...   \n",
       "191     8654                77                  37.0                  57   \n",
       "196     8528                51                  36.0                  51   \n",
       "197     8528                51                  37.0                  56   \n",
       "202     8602                47                  28.0                  58   \n",
       "203     8602                46                  36.0                  54   \n",
       "\n",
       "     chanceCreationPassing  chanceCreationCrossing  chanceCreationShooting  \\\n",
       "4                       28                      55                      64   \n",
       "5                       28                      44                      46   \n",
       "10                      63                      48                      56   \n",
       "11                      60                      48                      38   \n",
       "16                      77                      71                      56   \n",
       "..                     ...                     ...                     ...   \n",
       "191                     68                      73                      29   \n",
       "196                     52                      55                      57   \n",
       "197                     52                      59                      40   \n",
       "202                     55                      64                      56   \n",
       "203                     55                      47                      48   \n",
       "\n",
       "     defencePressure  defenceAggression  defenceTeamWidth  \n",
       "4                 51                 44                52  \n",
       "5                 51                 44                52  \n",
       "10                39                 42                52  \n",
       "11                35                 44                54  \n",
       "16                42                 48                54  \n",
       "..               ...                ...               ...  \n",
       "191               30                 37                41  \n",
       "196               62                 57                44  \n",
       "197               62                 48                44  \n",
       "202               47                 48                52  \n",
       "203               47                 48                55  \n",
       "\n",
       "[68 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(team_id):\n",
    "    team = teams_data[teams_data['team_id']==team_id]\n",
    "    team = team.loc[:,'buildUpPlaySpeed':].mean()\n",
    "    team = team.to_dict()\n",
    "    return team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gen(df):\n",
    "    home_team_ids = df.home_team_id\n",
    "    away_team_ids = df.away_team_id\n",
    "    l_home_teams = []\n",
    "    l_away_teams = []\n",
    "    for i in home_team_ids:\n",
    "        l_home_teams.append(gen_data(i))\n",
    "    for j in away_team_ids:\n",
    "        l_away_teams.append(gen_data(j))\n",
    "    l_home_teams = pd.DataFrame(l_home_teams)\n",
    "    l_away_teams = pd.DataFrame(l_away_teams)\n",
    "    l_home_teams = l_home_teams.rename(columns = {'buildUpPlaySpeed':'home_buildUpPlaySpeed','buildUpPlayDribbling':'home_buildUpPlayDribbling','buildUpPlayPassing':'home_buildUpPlayPassing','chanceCreationPassing':'home_chanceCreationPassing','chanceCreationCrossing':'home_chanceCreationCrossing','chanceCreationShooting':'home_chanceCreationShooting','defencePressure':'home_defencePressure','defenceAggression':'home_defenceAggression','defenceTeamWidth':'home_defenceTeamWidth'})\n",
    "    l_away_teams = l_away_teams.rename(columns = {'buildUpPlaySpeed':'away_buildUpPlaySpeed','buildUpPlayDribbling':'away_buildUpPlayDribbling','buildUpPlayPassing':'away_buildUpPlayPassing','chanceCreationPassing':'away_chanceCreationPassing','chanceCreationCrossing':'away_chanceCreationCrossing','chanceCreationShooting':'away_chanceCreationShooting','defencePressure':'away_defencePressure','defenceAggression':'away_defenceAggression','defenceTeamWidth':'away_defenceTeamWidth'})\n",
    "    return l_home_teams,l_away_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "home_team_train,away_team_train = gen(epl_matches_train)\n",
    "train_data = home_team_train.join(away_team_train)\n",
    "train_data_matrix = train_data.to_numpy()\n",
    "train_label = np.array(list(epl_matches_train.results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "home_team_test,away_team_test = gen(epl_matches_test)\n",
    "test_data = home_team_test.join(away_team_test)\n",
    "test_data_matrix = test_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 10 candidates, totalling 200 fits\n",
      "[CV] C=1e-06 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.6s\n",
      "[CV] C=1e-06 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-06 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.5s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.5s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.5s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.5s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.464, test=0.459), total=   0.5s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.464, test=0.459), total=   0.5s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.463, test=0.466), total=   0.5s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=0.001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.464, test=0.459), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.463, test=0.466), total=   0.5s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.463, test=0.466), total=   0.5s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.463, test=0.466), total=   0.5s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.463, test=0.466), total=   0.5s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.463, test=0.466), total=   0.5s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.463, test=0.466), total=   0.4s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.463, test=0.466), total=   0.5s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.463, test=0.466), total=   0.5s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.463, test=0.466), total=   0.5s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.463, test=0.466), total=   0.5s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.464, test=0.459), total=   0.5s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.464, test=0.459), total=   0.5s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.464, test=0.459), total=   0.5s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.464, test=0.459), total=   0.5s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.464, test=0.459), total=   0.5s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.464, test=0.459), total=   0.5s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.464, test=0.459), total=   0.5s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.463, test=0.466), total=   0.5s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.463, test=0.466), total=   0.5s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.463, test=0.466), total=   0.5s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.463, test=0.466), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.520, test=0.481), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.517, test=0.504), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.522, test=0.504), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.515, test=0.534), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.518, test=0.519), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.518, test=0.511), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.518, test=0.504), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.519, test=0.474), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.516, test=0.526), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.518, test=0.481), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.514, test=0.526), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.515, test=0.504), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.515, test=0.526), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.516, test=0.534), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.514, test=0.511), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.518, test=0.504), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.511, test=0.579), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.515, test=0.504), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=0.1, score=(train=0.517, test=0.526), total=   0.5s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.521, test=0.474), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.548, test=0.489), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.546, test=0.541), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.545, test=0.526), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.541, test=0.549), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.544, test=0.556), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.545, test=0.526), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.549, test=0.519), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.548, test=0.481), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.541, test=0.549), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.547, test=0.504), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.548, test=0.534), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.546, test=0.549), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.545, test=0.549), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.545, test=0.519), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.542, test=0.549), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.548, test=0.534), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.544, test=0.586), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.547, test=0.526), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.543, test=0.564), total=   0.5s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.550, test=0.459), total=   0.5s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.614, test=0.481), total=   0.6s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.611, test=0.504), total=   0.6s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.617, test=0.489), total=   0.6s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.611, test=0.519), total=   0.6s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.609, test=0.519), total=   0.6s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.614, test=0.481), total=   0.6s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.611, test=0.511), total=   0.6s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.612, test=0.414), total=   0.6s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.619, test=0.481), total=   0.6s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.611, test=0.496), total=   0.7s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.610, test=0.496), total=   0.7s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.615, test=0.489), total=   0.6s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.613, test=0.526), total=   0.6s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.612, test=0.549), total=   0.6s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.610, test=0.549), total=   0.7s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.611, test=0.511), total=   0.6s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.616, test=0.496), total=   0.7s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.608, test=0.519), total=   0.6s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.613, test=0.489), total=   0.7s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.610, test=0.436), total=   0.6s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.669, test=0.451), total=   1.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.665, test=0.504), total=   1.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.671, test=0.391), total=   1.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.665, test=0.541), total=   1.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.668, test=0.466), total=   1.3s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.670, test=0.421), total=   1.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.664, test=0.474), total=   1.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.670, test=0.421), total=   1.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.671, test=0.406), total=   1.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.668, test=0.481), total=   1.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.668, test=0.489), total=   1.3s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.666, test=0.474), total=   1.3s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.663, test=0.496), total=   1.3s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.664, test=0.511), total=   1.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.663, test=0.489), total=   1.3s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.669, test=0.451), total=   1.2s\n",
      "[CV] C=100.0 .........................................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=100.0, score=(train=0.668, test=0.474), total=   1.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.663, test=0.496), total=   1.3s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.666, test=0.459), total=   1.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.669, test=0.429), total=   1.1s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.681, test=0.421), total=   2.1s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.677, test=0.511), total=   2.2s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.683, test=0.398), total=   2.1s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.678, test=0.534), total=   2.2s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.680, test=0.466), total=   2.1s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.682, test=0.414), total=   2.1s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.675, test=0.504), total=   2.1s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.681, test=0.421), total=   2.1s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.682, test=0.376), total=   2.0s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.679, test=0.444), total=   2.0s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.681, test=0.466), total=   2.1s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.678, test=0.466), total=   2.3s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.676, test=0.504), total=   2.1s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.676, test=0.474), total=   2.2s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.676, test=0.489), total=   2.2s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.678, test=0.429), total=   2.3s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.679, test=0.459), total=   2.2s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.675, test=0.534), total=   2.2s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.677, test=0.489), total=   2.0s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.681, test=0.406), total=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 10 candidates, totalling 200 fits\n",
      "[CV] C=1e-06 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.9s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.1s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.1s\n",
      "[CV] C=1e-06 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.1s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.1s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.0s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.1s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.1s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.1s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.464, test=0.459), total=   0.1s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.464, test=0.459), total=   0.1s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.464, test=0.459), total=   0.1s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.464, test=0.459), total=   0.0s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.464, test=0.459), total=   0.1s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.464, test=0.459), total=   0.1s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.464, test=0.459), total=   0.1s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.1s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.1s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.1s\n",
      "[CV] C=1e-06 .........................................................\n",
      "[CV] ......... C=1e-06, score=(train=0.463, test=0.466), total=   0.1s\n",
      "[CV] C=1e-05 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=1e-05, score=(train=0.512, test=0.504), total=   0.2s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.510, test=0.511), total=   0.0s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.512, test=0.504), total=   0.1s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.510, test=0.511), total=   0.1s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.506, test=0.489), total=   0.1s\n",
      "[CV] C=1e-05 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=1e-05, score=(train=0.510, test=0.511), total=   0.1s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.508, test=0.489), total=   0.1s\n",
      "[CV] C=1e-05 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=1e-05, score=(train=0.511, test=0.489), total=   0.1s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.510, test=0.511), total=   0.1s\n",
      "[CV] C=1e-05 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=1e-05, score=(train=0.513, test=0.474), total=   0.2s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.509, test=0.519), total=   0.1s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.510, test=0.511), total=   0.1s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.509, test=0.504), total=   0.1s\n",
      "[CV] C=1e-05 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=1e-05, score=(train=0.506, test=0.526), total=   0.2s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.510, test=0.504), total=   0.0s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.511, test=0.511), total=   0.1s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.506, test=0.556), total=   0.0s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.509, test=0.504), total=   0.1s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.509, test=0.519), total=   0.1s\n",
      "[CV] C=1e-05 .........................................................\n",
      "[CV] ......... C=1e-05, score=(train=0.511, test=0.496), total=   0.1s\n",
      "[CV] C=0.0001 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=0.0001, score=(train=0.528, test=0.511), total=   0.2s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.526, test=0.534), total=   0.1s\n",
      "[CV] C=0.0001 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=0.0001, score=(train=0.527, test=0.519), total=   0.2s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.522, test=0.549), total=   0.2s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.522, test=0.511), total=   0.2s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.524, test=0.526), total=   0.2s\n",
      "[CV] C=0.0001 ........................................................"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] ........ C=0.0001, score=(train=0.524, test=0.519), total=   0.1s\n",
      "[CV] C=0.0001 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=0.0001, score=(train=0.527, test=0.481), total=   0.2s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.522, test=0.541), total=   0.1s\n",
      "[CV] C=0.0001 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=0.0001, score=(train=0.524, test=0.474), total=   0.2s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.524, test=0.511), total=   0.2s\n",
      "[CV] C=0.0001 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=0.0001, score=(train=0.523, test=0.526), total=   0.2s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.524, test=0.519), total=   0.2s\n",
      "[CV] C=0.0001 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=0.0001, score=(train=0.528, test=0.511), total=   0.2s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.524, test=0.534), total=   0.1s\n",
      "[CV] C=0.0001 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=0.0001, score=(train=0.527, test=0.526), total=   0.2s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.523, test=0.594), total=   0.1s\n",
      "[CV] C=0.0001 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=0.0001, score=(train=0.523, test=0.496), total=   0.2s\n",
      "[CV] C=0.0001 ........................................................\n",
      "[CV] ........ C=0.0001, score=(train=0.528, test=0.519), total=   0.2s\n",
      "[CV] C=0.0001 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=0.0001, score=(train=0.525, test=0.504), total=   0.2s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.529, test=0.496), total=   0.2s\n",
      "[CV] C=0.001 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=0.001, score=(train=0.528, test=0.526), total=   0.2s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.530, test=0.496), total=   0.1s\n",
      "[CV] C=0.001 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=0.001, score=(train=0.525, test=0.541), total=   0.2s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.526, test=0.541), total=   0.2s\n",
      "[CV] C=0.001 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=0.001, score=(train=0.525, test=0.519), total=   0.2s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.527, test=0.534), total=   0.2s\n",
      "[CV] C=0.001 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=0.001, score=(train=0.530, test=0.504), total=   0.2s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.526, test=0.541), total=   0.2s\n",
      "[CV] C=0.001 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=0.001, score=(train=0.528, test=0.504), total=   0.2s\n",
      "[CV] C=0.001 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=0.001, score=(train=0.529, test=0.541), total=   0.2s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.526, test=0.511), total=   0.1s\n",
      "[CV] C=0.001 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=0.001, score=(train=0.528, test=0.556), total=   0.2s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.527, test=0.519), total=   0.2s\n",
      "[CV] C=0.001 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=0.001, score=(train=0.526, test=0.541), total=   0.2s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.531, test=0.489), total=   0.2s\n",
      "[CV] C=0.001 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=0.001, score=(train=0.524, test=0.594), total=   0.1s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.525, test=0.504), total=   0.1s\n",
      "[CV] C=0.001 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=0.001, score=(train=0.527, test=0.519), total=   0.2s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] ......... C=0.001, score=(train=0.527, test=0.489), total=   0.1s\n",
      "[CV] C=0.01 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.01, score=(train=0.533, test=0.496), total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.527, test=0.534), total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.01, score=(train=0.531, test=0.481), total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.526, test=0.541), total=   0.1s\n",
      "[CV] C=0.01 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.01, score=(train=0.528, test=0.549), total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.530, test=0.504), total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.01, score=(train=0.527, test=0.526), total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.533, test=0.496), total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.01, score=(train=0.529, test=0.541), total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.528, test=0.519), total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.01, score=(train=0.529, test=0.549), total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.531, test=0.511), total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.01, score=(train=0.529, test=0.556), total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.526, test=0.519), total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.01, score=(train=0.525, test=0.534), total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.531, test=0.489), total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.01, score=(train=0.526, test=0.594), total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.532, test=0.496), total=   0.1s\n",
      "[CV] C=0.01 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=0.01, score=(train=0.529, test=0.526), total=   0.2s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] .......... C=0.01, score=(train=0.529, test=0.489), total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=0.1, score=(train=0.533, test=0.496), total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.528, test=0.526), total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=0.1, score=(train=0.531, test=0.481), total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.527, test=0.534), total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=0.1, score=(train=0.526, test=0.549), total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.529, test=0.504), total=   0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.529, test=0.526), total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.532, test=0.496), total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=0.1, score=(train=0.528, test=0.526), total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.525, test=0.511), total=   0.1s\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=0.1, score=(train=0.528, test=0.541), total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.532, test=0.511), total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=0.1, score=(train=0.529, test=0.564), total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.530, test=0.519), total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=0.1, score=(train=0.526, test=0.534), total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.531, test=0.489), total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=0.1, score=(train=0.526, test=0.594), total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.531, test=0.504), total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=0.1, score=(train=0.528, test=0.519), total=   0.2s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ........... C=0.1, score=(train=0.530, test=0.496), total=   0.2s\n",
      "[CV] C=1.0 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=1.0, score=(train=0.533, test=0.489), total=   0.2s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.528, test=0.534), total=   0.2s\n",
      "[CV] C=1.0 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=1.0, score=(train=0.532, test=0.489), total=   0.1s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.526, test=0.534), total=   0.1s\n",
      "[CV] C=1.0 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=1.0, score=(train=0.526, test=0.549), total=   0.2s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.530, test=0.504), total=   0.2s\n",
      "[CV] C=1.0 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=1.0, score=(train=0.530, test=0.526), total=   0.2s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.531, test=0.504), total=   0.1s\n",
      "[CV] C=1.0 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=1.0, score=(train=0.528, test=0.534), total=   0.2s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.527, test=0.511), total=   0.2s\n",
      "[CV] C=1.0 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=1.0, score=(train=0.530, test=0.549), total=   0.2s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.531, test=0.511), total=   0.1s\n",
      "[CV] C=1.0 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=1.0, score=(train=0.528, test=0.564), total=   0.2s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.530, test=0.519), total=   0.2s\n",
      "[CV] C=1.0 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=1.0, score=(train=0.526, test=0.519), total=   0.2s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.531, test=0.489), total=   0.2s\n",
      "[CV] C=1.0 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=1.0, score=(train=0.525, test=0.594), total=   0.2s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.532, test=0.496), total=   0.1s\n",
      "[CV] C=1.0 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... C=1.0, score=(train=0.528, test=0.526), total=   0.2s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ........... C=1.0, score=(train=0.530, test=0.496), total=   0.1s\n",
      "[CV] C=10.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=10.0, score=(train=0.535, test=0.489), total=   0.2s\n",
      "[CV] C=10.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=10.0, score=(train=0.528, test=0.526), total=   0.2s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.532, test=0.489), total=   0.2s\n",
      "[CV] C=10.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=10.0, score=(train=0.526, test=0.534), total=   0.2s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.527, test=0.549), total=   0.2s\n",
      "[CV] C=10.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=10.0, score=(train=0.530, test=0.504), total=   0.2s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.529, test=0.526), total=   0.2s\n",
      "[CV] C=10.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=10.0, score=(train=0.532, test=0.496), total=   0.2s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.529, test=0.534), total=   0.1s\n",
      "[CV] C=10.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=10.0, score=(train=0.526, test=0.504), total=   0.2s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.529, test=0.549), total=   0.2s\n",
      "[CV] C=10.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=10.0, score=(train=0.531, test=0.511), total=   0.1s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.527, test=0.556), total=   0.2s\n",
      "[CV] C=10.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=10.0, score=(train=0.530, test=0.519), total=   0.2s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.524, test=0.526), total=   0.2s\n",
      "[CV] C=10.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=10.0, score=(train=0.532, test=0.496), total=   0.2s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.525, test=0.602), total=   0.2s\n",
      "[CV] C=10.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=10.0, score=(train=0.532, test=0.496), total=   0.2s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .......... C=10.0, score=(train=0.529, test=0.526), total=   0.2s\n",
      "[CV] C=10.0 .........................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] .......... C=10.0, score=(train=0.532, test=0.489), total=   0.1s\n",
      "[CV] C=100.0 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=100.0, score=(train=0.534, test=0.504), total=   0.2s\n",
      "[CV] C=100.0 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=100.0, score=(train=0.529, test=0.526), total=   0.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.529, test=0.489), total=   0.2s\n",
      "[CV] C=100.0 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=100.0, score=(train=0.525, test=0.534), total=   0.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.529, test=0.549), total=   0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.529, test=0.496), total=   0.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.531, test=0.526), total=   0.2s\n",
      "[CV] C=100.0 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=100.0, score=(train=0.531, test=0.496), total=   0.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.529, test=0.534), total=   0.2s\n",
      "[CV] C=100.0 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=100.0, score=(train=0.527, test=0.511), total=   0.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.531, test=0.541), total=   0.2s\n",
      "[CV] C=100.0 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=100.0, score=(train=0.531, test=0.511), total=   0.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.527, test=0.556), total=   0.2s\n",
      "[CV] C=100.0 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=100.0, score=(train=0.530, test=0.519), total=   0.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.524, test=0.519), total=   0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.531, test=0.496), total=   0.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.526, test=0.594), total=   0.2s\n",
      "[CV] C=100.0 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=100.0, score=(train=0.529, test=0.496), total=   0.2s\n",
      "[CV] C=100.0 .........................................................\n",
      "[CV] ......... C=100.0, score=(train=0.529, test=0.526), total=   0.2s\n",
      "[CV] C=100.0 .........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... C=100.0, score=(train=0.528, test=0.481), total=   0.2s\n",
      "[CV] C=1000.0 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=1000.0, score=(train=0.535, test=0.489), total=   0.2s\n",
      "[CV] C=1000.0 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=1000.0, score=(train=0.528, test=0.526), total=   0.2s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.532, test=0.489), total=   0.1s\n",
      "[CV] C=1000.0 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=1000.0, score=(train=0.526, test=0.534), total=   0.2s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.528, test=0.549), total=   0.2s\n",
      "[CV] C=1000.0 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=1000.0, score=(train=0.529, test=0.496), total=   0.2s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.528, test=0.526), total=   0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.529, test=0.496), total=   0.2s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.529, test=0.534), total=   0.2s\n",
      "[CV] C=1000.0 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=1000.0, score=(train=0.526, test=0.511), total=   0.2s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.528, test=0.549), total=   0.2s\n",
      "[CV] C=1000.0 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=1000.0, score=(train=0.530, test=0.511), total=   0.2s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.528, test=0.556), total=   0.2s\n",
      "[CV] C=1000.0 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=1000.0, score=(train=0.526, test=0.519), total=   0.2s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.525, test=0.519), total=   0.2s\n",
      "[CV] C=1000.0 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=1000.0, score=(train=0.530, test=0.489), total=   0.2s\n",
      "[CV] C=1000.0 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=1000.0, score=(train=0.524, test=0.602), total=   0.2s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.531, test=0.496), total=   0.1s\n",
      "[CV] C=1000.0 ........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:   30.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=1000.0, score=(train=0.527, test=0.526), total=   0.2s\n",
      "[CV] C=1000.0 ........................................................\n",
      "[CV] ........ C=1000.0, score=(train=0.529, test=0.474), total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model_l = [SVC(),LogisticRegression(multi_class='multinomial')]\n",
    "model_acc = []\n",
    "model_params = []\n",
    "for i in range(2):\n",
    "    clf = model_l[i]\n",
    "    param_grid = {'C': 10. ** np.arange(-6, 4)}\n",
    "    grid_search = GridSearchCV(clf, param_grid=param_grid, cv=20, verbose=3, return_train_score=True)\n",
    "    grid_search.fit(train_data_matrix, train_label)\n",
    "    model_acc.append(grid_search.best_score_)\n",
    "    model_params.append(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l2 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l2, score=(train=0.498, test=0.470), total=   0.4s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l2 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l2, score=(train=0.498, test=0.485), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l2 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, loss=hinge, penalty=l2, score=(train=0.480, test=0.481), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l2 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l2, score=(train=0.254, test=0.256), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l2 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l2, score=(train=0.254, test=0.256), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l2 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l2, score=(train=0.528, test=0.511), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l2 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l2, score=(train=0.254, test=0.252), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l2 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l2, score=(train=0.518, test=0.549), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l2 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l2, score=(train=0.485, test=0.500), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l2 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l2, score=(train=0.484, test=0.459), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l1 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l1, score=(train=0.523, test=0.485), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l1 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l1, score=(train=0.462, test=0.462), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l1 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l1, score=(train=0.484, test=0.477), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l1 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l1, score=(train=0.525, test=0.508), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l1 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l1, score=(train=0.464, test=0.462), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l1 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l1, score=(train=0.324, test=0.305), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l1 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l1, score=(train=0.260, test=0.267), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l1 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l1, score=(train=0.254, test=0.252), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l1 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l1, score=(train=0.515, test=0.534), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=l1 ............................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=l1, score=(train=0.350, test=0.350), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=none ..........................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=none, score=(train=0.294, test=0.308), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=none ..........................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=none, score=(train=0.508, test=0.496), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=none ..........................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=none, score=(train=0.464, test=0.462), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=none ..........................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=none, score=(train=0.467, test=0.462), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=none ..........................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=none, score=(train=0.430, test=0.395), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=none ..........................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=none, score=(train=0.271, test=0.274), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=none ..........................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=none, score=(train=0.494, test=0.511), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=none ..........................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=none, score=(train=0.512, test=0.549), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=none ..........................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=none, score=(train=0.476, test=0.500), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=hinge, penalty=none ..........................\n",
      "[CV]  alpha=0.0001, loss=hinge, penalty=none, score=(train=0.466, test=0.447), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l2 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l2, score=(train=0.470, test=0.455), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l2 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l2, score=(train=0.362, test=0.368), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l2 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l2, score=(train=0.326, test=0.346), total=   0.3s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l2 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l2, score=(train=0.472, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l2 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l2, score=(train=0.448, test=0.432), total=   0.3s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l2 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l2, score=(train=0.469, test=0.470), total=   0.3s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l2 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l2, score=(train=0.502, test=0.500), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l2 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l2, score=(train=0.509, test=0.560), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l2 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l2, score=(train=0.470, test=0.470), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l2 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l2, score=(train=0.487, test=0.492), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l1 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l1, score=(train=0.345, test=0.342), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l1 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l1, score=(train=0.440, test=0.436), total=   0.3s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l1 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l1, score=(train=0.518, test=0.538), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l1 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l1, score=(train=0.285, test=0.282), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l1 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l1, score=(train=0.467, test=0.477), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l1 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l1, score=(train=0.459, test=0.451), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l1 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l1, score=(train=0.309, test=0.312), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l1 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l1, score=(train=0.519, test=0.523), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l1 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l1, score=(train=0.465, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=l1 ..............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=l1, score=(train=0.259, test=0.252), total=   0.3s\n",
      "[CV] alpha=0.0001, loss=log, penalty=none ............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=none, score=(train=0.301, test=0.293), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=none ............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=none, score=(train=0.492, test=0.500), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=none ............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=none, score=(train=0.309, test=0.338), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=none ............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, loss=log, penalty=none, score=(train=0.371, test=0.346), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=none ............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=none, score=(train=0.518, test=0.500), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=none ............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=none, score=(train=0.485, test=0.481), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=none ............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=none, score=(train=0.398, test=0.436), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=none ............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=none, score=(train=0.479, test=0.470), total=   0.3s\n",
      "[CV] alpha=0.0001, loss=log, penalty=none ............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=none, score=(train=0.464, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=log, penalty=none ............................\n",
      "[CV]  alpha=0.0001, loss=log, penalty=none, score=(train=0.255, test=0.252), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l2 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l2, score=(train=0.320, test=0.316), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l2 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l2, score=(train=0.333, test=0.342), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l2 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l2, score=(train=0.433, test=0.451), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l2 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l2, score=(train=0.305, test=0.286), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l2 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l2, score=(train=0.323, test=0.293), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l2 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l2, score=(train=0.311, test=0.297), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l2 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l2, score=(train=0.363, test=0.380), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l2 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l2, score=(train=0.254, test=0.252), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l2 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l2, score=(train=0.480, test=0.474), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l2 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l2, score=(train=0.396, test=0.380), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l1 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l1, score=(train=0.525, test=0.489), total=   0.3s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l1 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l1, score=(train=0.314, test=0.323), total=   0.3s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l1 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l1, score=(train=0.501, test=0.508), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l1 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l1, score=(train=0.463, test=0.462), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l1 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l1, score=(train=0.467, test=0.462), total=   0.3s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l1 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l1, score=(train=0.363, test=0.357), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l1 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l1, score=(train=0.464, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l1 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l1, score=(train=0.467, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l1 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l1, score=(train=0.421, test=0.421), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=l1 ....................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=l1, score=(train=0.421, test=0.410), total=   0.3s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=none ..................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=none, score=(train=0.376, test=0.368), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=none ..................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=none, score=(train=0.464, test=0.462), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=none ..................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=none, score=(train=0.282, test=0.282), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=none ..................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=none, score=(train=0.284, test=0.274), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=none ..................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=none, score=(train=0.523, test=0.508), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=none ..................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=none, score=(train=0.479, test=0.477), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=none ..................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=none, score=(train=0.500, test=0.523), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=none ..................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=none, score=(train=0.442, test=0.481), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=none ..................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=none, score=(train=0.458, test=0.470), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=squared_hinge, penalty=none ..................\n",
      "[CV]  alpha=0.0001, loss=squared_hinge, penalty=none, score=(train=0.270, test=0.263), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l2 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l2, score=(train=0.254, test=0.256), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l2 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l2, score=(train=0.443, test=0.414), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l2 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l2, score=(train=0.300, test=0.320), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l2 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l2, score=(train=0.498, test=0.485), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l2 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l2, score=(train=0.254, test=0.256), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l2 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l2, score=(train=0.363, test=0.331), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l2 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l2, score=(train=0.296, test=0.301), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l2 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l2, score=(train=0.482, test=0.489), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l2 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l2, score=(train=0.455, test=0.485), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l2 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l2, score=(train=0.260, test=0.252), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l1 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l1, score=(train=0.469, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l1 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l1, score=(train=0.472, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l1 ...................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l1, score=(train=0.413, test=0.395), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l1 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l1, score=(train=0.496, test=0.466), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l1 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l1, score=(train=0.433, test=0.440), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l1 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l1, score=(train=0.336, test=0.308), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l1 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l1, score=(train=0.466, test=0.481), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l1 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l1, score=(train=0.446, test=0.474), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l1 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l1, score=(train=0.498, test=0.500), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=l1 ...................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=l1, score=(train=0.254, test=0.252), total=   0.2s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=none .................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=none, score=(train=0.442, test=0.447), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=none .................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=none, score=(train=0.494, test=0.481), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=none .................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=none, score=(train=0.466, test=0.466), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=none .................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=none, score=(train=0.527, test=0.489), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=none .................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=none, score=(train=0.256, test=0.256), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=none .................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=none, score=(train=0.477, test=0.440), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=none .................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=none, score=(train=0.397, test=0.444), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=none .................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=none, score=(train=0.463, test=0.466), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=none .................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=none, score=(train=0.526, test=0.541), total=   0.1s\n",
      "[CV] alpha=0.0001, loss=modified_huber, penalty=none .................\n",
      "[CV]  alpha=0.0001, loss=modified_huber, penalty=none, score=(train=0.528, test=0.504), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l2 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l2, score=(train=0.308, test=0.316), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l2 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l2, score=(train=0.509, test=0.504), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l2 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l2, score=(train=0.470, test=0.477), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l2 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l2, score=(train=0.475, test=0.444), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l2 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l2, score=(train=0.470, test=0.489), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l2 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l2, score=(train=0.509, test=0.508), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l2 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l2, score=(train=0.501, test=0.519), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l2 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l2, score=(train=0.490, test=0.496), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l2 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l2, score=(train=0.466, test=0.466), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l2 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l2, score=(train=0.464, test=0.462), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l1 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l1, score=(train=0.461, test=0.398), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l1 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l1, score=(train=0.488, test=0.496), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l1 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l1, score=(train=0.398, test=0.383), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l1 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l1, score=(train=0.465, test=0.462), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l1 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l1, score=(train=0.525, test=0.515), total=   0.2s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l1 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l1, score=(train=0.484, test=0.477), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l1 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l1, score=(train=0.462, test=0.462), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l1 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l1, score=(train=0.282, test=0.282), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l1 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l1, score=(train=0.470, test=0.474), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=l1 .............................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=l1, score=(train=0.458, test=0.421), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=none ...........................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=none, score=(train=0.475, test=0.447), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=none ...........................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=none, score=(train=0.526, test=0.474), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=none ...........................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=none, score=(train=0.514, test=0.504), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=none ...........................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=none, score=(train=0.464, test=0.462), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=none ...........................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=none, score=(train=0.525, test=0.515), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=none ...........................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=none, score=(train=0.287, test=0.278), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=none ...........................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=none, score=(train=0.284, test=0.289), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=none ...........................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=none, score=(train=0.475, test=0.534), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=none ...........................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=none, score=(train=0.344, test=0.335), total=   0.1s\n",
      "[CV] alpha=0.001, loss=hinge, penalty=none ...........................\n",
      "[CV]  alpha=0.001, loss=hinge, penalty=none, score=(train=0.472, test=0.447), total=   0.1s\n",
      "[CV] alpha=0.001, loss=log, penalty=l2 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l2, score=(train=0.464, test=0.462), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=l2 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l2, score=(train=0.330, test=0.342), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=l2 ...............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, loss=log, penalty=l2, score=(train=0.454, test=0.462), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=l2 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l2, score=(train=0.489, test=0.459), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=l2 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l2, score=(train=0.463, test=0.462), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=l2 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l2, score=(train=0.345, test=0.335), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=l2 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l2, score=(train=0.459, test=0.500), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=l2 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l2, score=(train=0.471, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=l2 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l2, score=(train=0.467, test=0.489), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=l2 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l2, score=(train=0.320, test=0.297), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=l1 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l1, score=(train=0.382, test=0.391), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=l1 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l1, score=(train=0.287, test=0.274), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=l1 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l1, score=(train=0.466, test=0.466), total=   0.1s\n",
      "[CV] alpha=0.001, loss=log, penalty=l1 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l1, score=(train=0.489, test=0.481), total=   0.1s\n",
      "[CV] alpha=0.001, loss=log, penalty=l1 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l1, score=(train=0.336, test=0.323), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=l1 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l1, score=(train=0.495, test=0.447), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=l1 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l1, score=(train=0.397, test=0.406), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=l1 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l1, score=(train=0.484, test=0.474), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=l1 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l1, score=(train=0.495, test=0.504), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=l1 ...............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=l1, score=(train=0.464, test=0.462), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=none .............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=none, score=(train=0.520, test=0.455), total=   0.1s\n",
      "[CV] alpha=0.001, loss=log, penalty=none .............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=none, score=(train=0.496, test=0.489), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=none .............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=none, score=(train=0.464, test=0.462), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=none .............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=none, score=(train=0.478, test=0.447), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=none .............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=none, score=(train=0.466, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=none .............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=none, score=(train=0.518, test=0.519), total=   0.1s\n",
      "[CV] alpha=0.001, loss=log, penalty=none .............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=none, score=(train=0.289, test=0.312), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=none .............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=none, score=(train=0.368, test=0.372), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=none .............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=none, score=(train=0.269, test=0.263), total=   0.2s\n",
      "[CV] alpha=0.001, loss=log, penalty=none .............................\n",
      "[CV]  alpha=0.001, loss=log, penalty=none, score=(train=0.442, test=0.417), total=   0.2s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l2 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l2, score=(train=0.396, test=0.398), total=   0.2s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l2 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l2, score=(train=0.495, test=0.485), total=   0.1s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l2 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l2, score=(train=0.414, test=0.406), total=   0.1s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l2 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l2, score=(train=0.530, test=0.500), total=   0.2s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l2 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l2, score=(train=0.353, test=0.327), total=   0.2s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l2 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l2, score=(train=0.510, test=0.504), total=   0.2s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l2 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l2, score=(train=0.295, test=0.305), total=   0.1s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l2 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l2, score=(train=0.520, test=0.530), total=   0.2s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l2 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l2, score=(train=0.298, test=0.282), total=   0.1s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l2 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l2, score=(train=0.520, test=0.511), total=   0.1s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l1 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l1, score=(train=0.470, test=0.466), total=   0.3s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l1 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l1, score=(train=0.468, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l1 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l1, score=(train=0.445, test=0.425), total=   0.3s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l1 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l1, score=(train=0.335, test=0.301), total=   0.3s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l1 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l1, score=(train=0.524, test=0.511), total=   0.3s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l1 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l1, score=(train=0.526, test=0.526), total=   0.3s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l1 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l1, score=(train=0.285, test=0.308), total=   0.3s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l1 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l1, score=(train=0.256, test=0.259), total=   0.2s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l1 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l1, score=(train=0.470, test=0.477), total=   0.2s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=l1 .....................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=l1, score=(train=0.419, test=0.398), total=   0.3s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=none ...................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=none, score=(train=0.381, test=0.361), total=   0.1s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=none ...................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=none, score=(train=0.393, test=0.372), total=   0.2s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=none ...................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=none, score=(train=0.470, test=0.462), total=   0.1s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=none ...................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=none, score=(train=0.516, test=0.500), total=   0.1s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=none ...................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=none, score=(train=0.464, test=0.462), total=   0.2s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=none ...................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=none, score=(train=0.507, test=0.496), total=   0.1s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=none ...................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=none, score=(train=0.514, test=0.534), total=   0.1s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=none ...................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=none, score=(train=0.405, test=0.410), total=   0.1s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=none ...................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=none, score=(train=0.466, test=0.466), total=   0.1s\n",
      "[CV] alpha=0.001, loss=squared_hinge, penalty=none ...................\n",
      "[CV]  alpha=0.001, loss=squared_hinge, penalty=none, score=(train=0.501, test=0.489), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l2 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l2, score=(train=0.500, test=0.459), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l2 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l2, score=(train=0.325, test=0.301), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l2 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l2, score=(train=0.254, test=0.256), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l2 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l2, score=(train=0.466, test=0.470), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l2 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l2, score=(train=0.513, test=0.481), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l2 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l2, score=(train=0.442, test=0.402), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l2 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l2, score=(train=0.255, test=0.259), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l2 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l2, score=(train=0.517, test=0.556), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l2 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l2, score=(train=0.496, test=0.500), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l2 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l2, score=(train=0.471, test=0.466), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l1 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l1, score=(train=0.523, test=0.489), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l1 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l1, score=(train=0.394, test=0.417), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l1 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l1, score=(train=0.510, test=0.508), total=   0.2s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l1 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l1, score=(train=0.528, test=0.496), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l1 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l1, score=(train=0.378, test=0.342), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l1 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l1, score=(train=0.431, test=0.425), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l1 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l1, score=(train=0.259, test=0.271), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l1 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l1, score=(train=0.510, test=0.504), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l1 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l1, score=(train=0.399, test=0.383), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=l1 ....................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=l1, score=(train=0.453, test=0.440), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=none ..................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=none, score=(train=0.319, test=0.323), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=none ..................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=none, score=(train=0.352, test=0.342), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=none ..................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=none, score=(train=0.501, test=0.519), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=none ..................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=none, score=(train=0.477, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=none ..................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=none, score=(train=0.472, test=0.470), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=none ..................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=none, score=(train=0.472, test=0.474), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=none ..................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=none, score=(train=0.497, test=0.526), total=   0.2s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=none ..................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=none, score=(train=0.464, test=0.466), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=none ..................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=none, score=(train=0.254, test=0.252), total=   0.1s\n",
      "[CV] alpha=0.001, loss=modified_huber, penalty=none ..................\n",
      "[CV]  alpha=0.001, loss=modified_huber, penalty=none, score=(train=0.478, test=0.451), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l2 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l2, score=(train=0.332, test=0.320), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l2 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l2, score=(train=0.472, test=0.470), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l2 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l2, score=(train=0.525, test=0.538), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l2 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l2, score=(train=0.363, test=0.335), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l2 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l2, score=(train=0.483, test=0.447), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l2 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l2, score=(train=0.506, test=0.504), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l2 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l2, score=(train=0.287, test=0.293), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l2 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l2, score=(train=0.453, test=0.459), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l2 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l2, score=(train=0.490, test=0.496), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l2 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l2, score=(train=0.330, test=0.335), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l1 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l1, score=(train=0.525, test=0.504), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l1 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l1, score=(train=0.518, test=0.492), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l1 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l1, score=(train=0.314, test=0.365), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l1 ..............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, loss=hinge, penalty=l1, score=(train=0.457, test=0.444), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l1 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l1, score=(train=0.422, test=0.406), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l1 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l1, score=(train=0.501, test=0.474), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l1 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l1, score=(train=0.439, test=0.466), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l1 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l1, score=(train=0.284, test=0.282), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l1 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l1, score=(train=0.488, test=0.489), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=l1 ..............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=l1, score=(train=0.328, test=0.301), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=none ............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=none, score=(train=0.477, test=0.429), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=none ............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=none, score=(train=0.284, test=0.274), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=none ............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=none, score=(train=0.521, test=0.538), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=none ............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=none, score=(train=0.312, test=0.286), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=none ............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=none, score=(train=0.421, test=0.402), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=none ............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=none, score=(train=0.530, test=0.519), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=none ............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=none, score=(train=0.470, test=0.477), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=none ............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=none, score=(train=0.478, test=0.485), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=none ............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=none, score=(train=0.259, test=0.248), total=   0.1s\n",
      "[CV] alpha=0.01, loss=hinge, penalty=none ............................\n",
      "[CV]  alpha=0.01, loss=hinge, penalty=none, score=(train=0.464, test=0.436), total=   0.1s\n",
      "[CV] alpha=0.01, loss=log, penalty=l2 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l2, score=(train=0.492, test=0.432), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=l2 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l2, score=(train=0.312, test=0.271), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=l2 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l2, score=(train=0.481, test=0.447), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=l2 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l2, score=(train=0.534, test=0.519), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=l2 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l2, score=(train=0.421, test=0.410), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=l2 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l2, score=(train=0.471, test=0.425), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=l2 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l2, score=(train=0.289, test=0.301), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=l2 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l2, score=(train=0.521, test=0.541), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=l2 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l2, score=(train=0.500, test=0.504), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=l2 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l2, score=(train=0.493, test=0.474), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=l1 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l1, score=(train=0.437, test=0.425), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=l1 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l1, score=(train=0.293, test=0.278), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=l1 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l1, score=(train=0.438, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=l1 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l1, score=(train=0.515, test=0.485), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=l1 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l1, score=(train=0.259, test=0.256), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=l1 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l1, score=(train=0.484, test=0.481), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=l1 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l1, score=(train=0.472, test=0.481), total=   0.1s\n",
      "[CV] alpha=0.01, loss=log, penalty=l1 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l1, score=(train=0.469, test=0.508), total=   0.1s\n",
      "[CV] alpha=0.01, loss=log, penalty=l1 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l1, score=(train=0.490, test=0.492), total=   0.1s\n",
      "[CV] alpha=0.01, loss=log, penalty=l1 ................................\n",
      "[CV]  alpha=0.01, loss=log, penalty=l1, score=(train=0.294, test=0.289), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=none ..............................\n",
      "[CV]  alpha=0.01, loss=log, penalty=none, score=(train=0.443, test=0.462), total=   0.1s\n",
      "[CV] alpha=0.01, loss=log, penalty=none ..............................\n",
      "[CV]  alpha=0.01, loss=log, penalty=none, score=(train=0.520, test=0.477), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=none ..............................\n",
      "[CV]  alpha=0.01, loss=log, penalty=none, score=(train=0.361, test=0.395), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=none ..............................\n",
      "[CV]  alpha=0.01, loss=log, penalty=none, score=(train=0.486, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=none ..............................\n",
      "[CV]  alpha=0.01, loss=log, penalty=none, score=(train=0.444, test=0.447), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=none ..............................\n",
      "[CV]  alpha=0.01, loss=log, penalty=none, score=(train=0.489, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=none ..............................\n",
      "[CV]  alpha=0.01, loss=log, penalty=none, score=(train=0.425, test=0.432), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=none ..............................\n",
      "[CV]  alpha=0.01, loss=log, penalty=none, score=(train=0.470, test=0.470), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=none ..............................\n",
      "[CV]  alpha=0.01, loss=log, penalty=none, score=(train=0.273, test=0.282), total=   0.2s\n",
      "[CV] alpha=0.01, loss=log, penalty=none ..............................\n",
      "[CV]  alpha=0.01, loss=log, penalty=none, score=(train=0.483, test=0.481), total=   0.2s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l2 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l2, score=(train=0.315, test=0.327), total=   0.2s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l2 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l2, score=(train=0.518, test=0.481), total=   0.1s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l2 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l2, score=(train=0.457, test=0.421), total=   0.1s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l2 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l2, score=(train=0.485, test=0.474), total=   0.1s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l2 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l2, score=(train=0.475, test=0.474), total=   0.2s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l2 ......................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l2, score=(train=0.397, test=0.387), total=   0.2s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l2 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l2, score=(train=0.467, test=0.530), total=   0.2s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l2 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l2, score=(train=0.254, test=0.252), total=   0.2s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l2 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l2, score=(train=0.503, test=0.511), total=   0.2s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l2 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l2, score=(train=0.270, test=0.271), total=   0.2s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l1 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l1, score=(train=0.528, test=0.462), total=   0.2s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l1 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l1, score=(train=0.370, test=0.391), total=   0.3s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l1 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l1, score=(train=0.526, test=0.526), total=   0.3s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l1 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l1, score=(train=0.484, test=0.470), total=   0.2s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l1 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l1, score=(train=0.434, test=0.414), total=   0.3s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l1 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l1, score=(train=0.463, test=0.462), total=   0.3s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l1 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l1, score=(train=0.263, test=0.267), total=   0.3s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l1 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l1, score=(train=0.504, test=0.500), total=   0.3s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l1 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l1, score=(train=0.367, test=0.380), total=   0.2s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=l1 ......................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=l1, score=(train=0.285, test=0.271), total=   0.2s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=none ....................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=none, score=(train=0.437, test=0.447), total=   0.2s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=none ....................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=none, score=(train=0.477, test=0.470), total=   0.2s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=none ....................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=none, score=(train=0.479, test=0.477), total=   0.1s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=none ....................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=none, score=(train=0.444, test=0.425), total=   0.1s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=none ....................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=none, score=(train=0.460, test=0.406), total=   0.2s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=none ....................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=none, score=(train=0.497, test=0.466), total=   0.1s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=none ....................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=none, score=(train=0.464, test=0.466), total=   0.1s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=none ....................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=none, score=(train=0.465, test=0.455), total=   0.1s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=none ....................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=none, score=(train=0.480, test=0.492), total=   0.1s\n",
      "[CV] alpha=0.01, loss=squared_hinge, penalty=none ....................\n",
      "[CV]  alpha=0.01, loss=squared_hinge, penalty=none, score=(train=0.371, test=0.342), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l2 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l2, score=(train=0.418, test=0.421), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l2 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l2, score=(train=0.463, test=0.462), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l2 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l2, score=(train=0.426, test=0.417), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l2 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l2, score=(train=0.439, test=0.402), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l2 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l2, score=(train=0.519, test=0.481), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l2 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l2, score=(train=0.527, test=0.515), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l2 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l2, score=(train=0.510, test=0.530), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l2 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l2, score=(train=0.525, test=0.553), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l2 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l2, score=(train=0.367, test=0.365), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l2 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l2, score=(train=0.487, test=0.455), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l1 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l1, score=(train=0.475, test=0.466), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l1 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l1, score=(train=0.382, test=0.361), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l1 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l1, score=(train=0.258, test=0.267), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l1 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l1, score=(train=0.493, test=0.492), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l1 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l1, score=(train=0.391, test=0.410), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l1 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l1, score=(train=0.405, test=0.372), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l1 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l1, score=(train=0.474, test=0.474), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l1 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l1, score=(train=0.484, test=0.485), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l1 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l1, score=(train=0.506, test=0.534), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=l1 .....................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=l1, score=(train=0.514, test=0.485), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=none ...................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=none, score=(train=0.413, test=0.414), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=none ...................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=none, score=(train=0.503, test=0.474), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=none ...................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=none, score=(train=0.502, test=0.504), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=none ...................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=none, score=(train=0.517, test=0.492), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=none ...................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=none, score=(train=0.530, test=0.492), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=none ...................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, loss=modified_huber, penalty=none, score=(train=0.494, test=0.466), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=none ...................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=none, score=(train=0.477, test=0.477), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=none ...................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=none, score=(train=0.330, test=0.350), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=none ...................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=none, score=(train=0.421, test=0.410), total=   0.1s\n",
      "[CV] alpha=0.01, loss=modified_huber, penalty=none ...................\n",
      "[CV]  alpha=0.01, loss=modified_huber, penalty=none, score=(train=0.497, test=0.474), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l2 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l2, score=(train=0.397, test=0.410), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l2 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l2, score=(train=0.519, test=0.515), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l2 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l2, score=(train=0.524, test=0.523), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l2 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l2, score=(train=0.516, test=0.489), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l2 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l2, score=(train=0.522, test=0.474), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l2 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l2, score=(train=0.525, test=0.515), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l2 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l2, score=(train=0.332, test=0.353), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l2 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l2, score=(train=0.321, test=0.327), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l2 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l2, score=(train=0.493, test=0.504), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l2 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l2, score=(train=0.457, test=0.429), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l1 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l1, score=(train=0.507, test=0.489), total=   0.0s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l1 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l1, score=(train=0.376, test=0.387), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l1 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l1, score=(train=0.363, test=0.387), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l1 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l1, score=(train=0.430, test=0.429), total=   0.0s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l1 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l1, score=(train=0.502, test=0.500), total=   0.0s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l1 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l1, score=(train=0.494, test=0.496), total=   0.0s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l1 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l1, score=(train=0.323, test=0.320), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l1 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l1, score=(train=0.342, test=0.357), total=   0.0s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l1 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l1, score=(train=0.467, test=0.504), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=l1 ...............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=l1, score=(train=0.508, test=0.508), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=none .............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=none, score=(train=0.279, test=0.293), total=   0.2s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=none .............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=none, score=(train=0.501, test=0.485), total=   0.2s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=none .............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=none, score=(train=0.521, test=0.508), total=   0.2s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=none .............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=none, score=(train=0.505, test=0.477), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=none .............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=none, score=(train=0.468, test=0.432), total=   0.2s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=none .............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=none, score=(train=0.500, test=0.474), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=none .............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=none, score=(train=0.442, test=0.481), total=   0.2s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=none .............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=none, score=(train=0.368, test=0.365), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=none .............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=none, score=(train=0.500, test=0.538), total=   0.1s\n",
      "[CV] alpha=0.1, loss=hinge, penalty=none .............................\n",
      "[CV]  alpha=0.1, loss=hinge, penalty=none, score=(train=0.518, test=0.477), total=   0.2s\n",
      "[CV] alpha=0.1, loss=log, penalty=l2 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l2, score=(train=0.463, test=0.447), total=   0.2s\n",
      "[CV] alpha=0.1, loss=log, penalty=l2 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l2, score=(train=0.456, test=0.447), total=   0.1s\n",
      "[CV] alpha=0.1, loss=log, penalty=l2 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l2, score=(train=0.480, test=0.477), total=   0.1s\n",
      "[CV] alpha=0.1, loss=log, penalty=l2 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l2, score=(train=0.318, test=0.301), total=   0.2s\n",
      "[CV] alpha=0.1, loss=log, penalty=l2 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l2, score=(train=0.473, test=0.481), total=   0.2s\n",
      "[CV] alpha=0.1, loss=log, penalty=l2 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l2, score=(train=0.501, test=0.500), total=   0.2s\n",
      "[CV] alpha=0.1, loss=log, penalty=l2 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l2, score=(train=0.377, test=0.391), total=   0.1s\n",
      "[CV] alpha=0.1, loss=log, penalty=l2 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l2, score=(train=0.511, test=0.545), total=   0.2s\n",
      "[CV] alpha=0.1, loss=log, penalty=l2 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l2, score=(train=0.498, test=0.515), total=   0.1s\n",
      "[CV] alpha=0.1, loss=log, penalty=l2 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l2, score=(train=0.503, test=0.492), total=   0.1s\n",
      "[CV] alpha=0.1, loss=log, penalty=l1 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l1, score=(train=0.332, test=0.305), total=   0.1s\n",
      "[CV] alpha=0.1, loss=log, penalty=l1 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l1, score=(train=0.457, test=0.421), total=   0.1s\n",
      "[CV] alpha=0.1, loss=log, penalty=l1 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l1, score=(train=0.507, test=0.515), total=   0.1s\n",
      "[CV] alpha=0.1, loss=log, penalty=l1 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l1, score=(train=0.468, test=0.462), total=   0.1s\n",
      "[CV] alpha=0.1, loss=log, penalty=l1 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l1, score=(train=0.493, test=0.470), total=   0.1s\n",
      "[CV] alpha=0.1, loss=log, penalty=l1 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l1, score=(train=0.472, test=0.492), total=   0.1s\n",
      "[CV] alpha=0.1, loss=log, penalty=l1 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l1, score=(train=0.475, test=0.481), total=   0.1s\n",
      "[CV] alpha=0.1, loss=log, penalty=l1 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l1, score=(train=0.498, test=0.515), total=   0.1s\n",
      "[CV] alpha=0.1, loss=log, penalty=l1 .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.1, loss=log, penalty=l1, score=(train=0.490, test=0.526), total=   0.1s\n",
      "[CV] alpha=0.1, loss=log, penalty=l1 .................................\n",
      "[CV]  alpha=0.1, loss=log, penalty=l1, score=(train=0.490, test=0.481), total=   0.1s\n",
      "[CV] alpha=0.1, loss=log, penalty=none ...............................\n",
      "[CV]  alpha=0.1, loss=log, penalty=none, score=(train=0.472, test=0.451), total=   0.2s\n",
      "[CV] alpha=0.1, loss=log, penalty=none ...............................\n",
      "[CV]  alpha=0.1, loss=log, penalty=none, score=(train=0.515, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.1, loss=log, penalty=none ...............................\n",
      "[CV]  alpha=0.1, loss=log, penalty=none, score=(train=0.484, test=0.496), total=   0.3s\n",
      "[CV] alpha=0.1, loss=log, penalty=none ...............................\n",
      "[CV]  alpha=0.1, loss=log, penalty=none, score=(train=0.470, test=0.470), total=   0.2s\n",
      "[CV] alpha=0.1, loss=log, penalty=none ...............................\n",
      "[CV]  alpha=0.1, loss=log, penalty=none, score=(train=0.525, test=0.515), total=   0.2s\n",
      "[CV] alpha=0.1, loss=log, penalty=none ...............................\n",
      "[CV]  alpha=0.1, loss=log, penalty=none, score=(train=0.498, test=0.492), total=   0.2s\n",
      "[CV] alpha=0.1, loss=log, penalty=none ...............................\n",
      "[CV]  alpha=0.1, loss=log, penalty=none, score=(train=0.491, test=0.523), total=   0.3s\n",
      "[CV] alpha=0.1, loss=log, penalty=none ...............................\n",
      "[CV]  alpha=0.1, loss=log, penalty=none, score=(train=0.452, test=0.466), total=   0.5s\n",
      "[CV] alpha=0.1, loss=log, penalty=none ...............................\n",
      "[CV]  alpha=0.1, loss=log, penalty=none, score=(train=0.502, test=0.538), total=   0.4s\n",
      "[CV] alpha=0.1, loss=log, penalty=none ...............................\n",
      "[CV]  alpha=0.1, loss=log, penalty=none, score=(train=0.523, test=0.530), total=   0.2s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l2 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l2, score=(train=0.398, test=0.391), total=   0.2s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l2 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l2, score=(train=0.452, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l2 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l2, score=(train=0.485, test=0.447), total=   0.2s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l2 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l2, score=(train=0.388, test=0.395), total=   0.2s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l2 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l2, score=(train=0.465, test=0.462), total=   0.2s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l2 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l2, score=(train=0.447, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l2 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l2, score=(train=0.435, test=0.474), total=   0.2s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l2 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l2, score=(train=0.427, test=0.455), total=   0.2s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l2 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l2, score=(train=0.413, test=0.421), total=   0.2s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l2 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l2, score=(train=0.464, test=0.462), total=   0.2s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l1 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l1, score=(train=0.274, test=0.267), total=   0.4s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l1 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l1, score=(train=0.479, test=0.489), total=   0.3s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l1 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l1, score=(train=0.460, test=0.459), total=   0.3s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l1 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l1, score=(train=0.439, test=0.451), total=   0.4s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l1 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l1, score=(train=0.439, test=0.436), total=   0.4s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l1 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l1, score=(train=0.475, test=0.451), total=   0.3s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l1 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l1, score=(train=0.418, test=0.466), total=   0.4s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l1 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l1, score=(train=0.321, test=0.335), total=   0.3s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l1 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l1, score=(train=0.474, test=0.489), total=   0.4s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=l1 .......................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=l1, score=(train=0.491, test=0.492), total=   0.4s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=none .....................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=none, score=(train=0.321, test=0.308), total=   0.2s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=none .....................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=none, score=(train=0.255, test=0.252), total=   0.2s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=none .....................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=none, score=(train=0.344, test=0.350), total=   0.3s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=none .....................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=none, score=(train=0.461, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=none .....................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=none, score=(train=0.256, test=0.263), total=   0.3s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=none .....................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=none, score=(train=0.494, test=0.466), total=   0.2s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=none .....................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=none, score=(train=0.396, test=0.432), total=   0.3s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=none .....................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=none, score=(train=0.464, test=0.466), total=   0.3s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=none .....................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=none, score=(train=0.499, test=0.474), total=   0.3s\n",
      "[CV] alpha=0.1, loss=squared_hinge, penalty=none .....................\n",
      "[CV]  alpha=0.1, loss=squared_hinge, penalty=none, score=(train=0.339, test=0.308), total=   0.3s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l2 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l2, score=(train=0.477, test=0.455), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l2 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l2, score=(train=0.523, test=0.500), total=   0.2s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l2 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l2, score=(train=0.495, test=0.474), total=   0.2s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l2 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l2, score=(train=0.496, test=0.470), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l2 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l2, score=(train=0.493, test=0.462), total=   0.2s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l2 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l2, score=(train=0.488, test=0.489), total=   0.2s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l2 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l2, score=(train=0.504, test=0.515), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l2 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l2, score=(train=0.463, test=0.462), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l2 ......................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l2, score=(train=0.486, test=0.481), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l2 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l2, score=(train=0.465, test=0.462), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l1 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l1, score=(train=0.510, test=0.496), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l1 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l1, score=(train=0.474, test=0.481), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l1 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l1, score=(train=0.361, test=0.368), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l1 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l1, score=(train=0.495, test=0.492), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l1 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l1, score=(train=0.467, test=0.440), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l1 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l1, score=(train=0.469, test=0.466), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l1 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l1, score=(train=0.501, test=0.523), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l1 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l1, score=(train=0.294, test=0.301), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l1 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l1, score=(train=0.479, test=0.496), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=l1 ......................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=l1, score=(train=0.474, test=0.447), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=none ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.1, loss=modified_huber, penalty=none, score=(train=0.442, test=0.444), total=   0.4s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=none ....................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=none, score=(train=0.504, test=0.470), total=   0.2s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=none ....................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=none, score=(train=0.261, test=0.271), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=none ....................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=none, score=(train=0.329, test=0.305), total=   0.2s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=none ....................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=none, score=(train=0.502, test=0.459), total=   0.2s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=none ....................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=none, score=(train=0.429, test=0.372), total=   0.2s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=none ....................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=none, score=(train=0.302, test=0.312), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=none ....................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=none, score=(train=0.512, test=0.500), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=none ....................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=none, score=(train=0.284, test=0.282), total=   0.1s\n",
      "[CV] alpha=0.1, loss=modified_huber, penalty=none ....................\n",
      "[CV]  alpha=0.1, loss=modified_huber, penalty=none, score=(train=0.459, test=0.455), total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 480 out of 480 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SGDClassifier(),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
       "                         'loss': ['hinge', 'log', 'squared_hinge',\n",
       "                                  'modified_huber'],\n",
       "                         'penalty': ['l2', 'l1', 'none']},\n",
       "             return_train_score=True, verbose=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier(max_iter=1000)\n",
    "param_grid2 = {\n",
    "    \"loss\" : [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\"],\n",
    "    \"alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"penalty\" : [\"l2\", \"l1\", \"none\"],\n",
    "}\n",
    "grid_search2 = GridSearchCV(sgd, param_grid=param_grid2, cv=10, verbose=3, return_train_score=True)\n",
    "grid_search2.fit(train_data_matrix,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.530451</td>\n",
       "      <td>{'C': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.523308</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.494737</td>\n",
       "      <td>{'alpha': 0.1, 'loss': 'log', 'penalty': 'none'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy  \\\n",
       "0                 SVC  0.530451   \n",
       "1  LogisticRegression  0.523308   \n",
       "2       SGDClassifier  0.494737   \n",
       "\n",
       "                                             Params  \n",
       "0                                        {'C': 1.0}  \n",
       "1                                      {'C': 0.001}  \n",
       "2  {'alpha': 0.1, 'loss': 'log', 'penalty': 'none'}  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model = ['SVC','LogisticRegression','SGDClassifier']\n",
    "Model_accuracy = model_acc+[grid_search2.best_score_]\n",
    "Model_params = model_params+[grid_search2.best_params_]\n",
    "df = {'Model':Model,'Accuracy':Model_accuracy,'Params':Model_params}\n",
    "df = pd.DataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subhash chandran\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "best_model = LogisticRegression(C=0.001)\n",
    "best_model.fit(train_data_matrix,train_label)\n",
    "prediction = best_model.predict(test_data_matrix)\n",
    "pred = {'match_id':list(epl_matches_test['match_id']),'result':prediction}\n",
    "pred = pd.DataFrame(pred)\n",
    "map = {0:'lose', 1:'draw', 2:'win'}\n",
    "pred.replace(map,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred.to_csv('prediction_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X,y,ratio):\n",
    "    permutation = np.array([i for i in range(len(X))])\n",
    "    np.random.shuffle(permutation)\n",
    "    X = np.array([X[i] for i in permutation])\n",
    "    y = np.array([y[i] for i in permutation])\n",
    "    split_index = int(ratio*X.shape[0])\n",
    "    train_data = X[:split_index]\n",
    "    train_label = y[:split_index]\n",
    "    valid_data = X[split_index:]\n",
    "    valid_label = y[split_index:]\n",
    "    return train_data,train_label,valid_data,valid_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(X,y,batch_size):\n",
    "    # Only take batch_size chunks (i.e. drop the remainder)\n",
    "    N = int(len(X) / batch_size) * batch_size\n",
    "    batches = []\n",
    "    for i in range(0, N, batch_size):\n",
    "        batches.append({\n",
    "            'x': torch.tensor(X[i:i+batch_size], dtype=torch.float32),\n",
    "            'y': torch.tensor(y[i:i+batch_size], dtype=torch.long\n",
    "        )})\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN,self).__init__()\n",
    "        self.fc1 = nn.Linear(18,10)\n",
    "        self.fc2 = nn.Linear(10,3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(split_ratio,batch_size,learning_rate,n_epochs):\n",
    "    nn_train_data,nn_train_label,nn_valid_data,nn_valid_label = split(train_data_matrix,train_label,split_ratio)\n",
    "    permutation = np.array([i for i in range(len(nn_train_data))])\n",
    "    np.random.shuffle(permutation)\n",
    "    nn_train_data = np.array([nn_train_data[i] for i in permutation])\n",
    "    nn_train_label = np.array([nn_train_label[i] for i in permutation])\n",
    "\n",
    "\n",
    "    train_batches = batchify(nn_train_data,nn_train_label,batch_size)\n",
    "    valid_batches = batchify(nn_valid_data,nn_valid_label,batch_size)\n",
    "\n",
    "\n",
    "    model = NN()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "\n",
    "#     total = 0\n",
    "#     count = {0:0,1:1,2:2}\n",
    "#     for batch in train_batches:\n",
    "#         for y in batch['y']:\n",
    "#             count[int(y)]+=1\n",
    "#             total+=1\n",
    "#     for i in count:\n",
    "#         print(f\"{i} : {count[i]/total*100}\")\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch in train_batches:\n",
    "            data = batch['x']\n",
    "            label = batch['y']\n",
    "            scores = model(data)\n",
    "            loss = criterion(scores,label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return valid_batches,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader,model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_batches:\n",
    "            X = batch['x']\n",
    "            y = batch['y']\n",
    "            scores = model(X)\n",
    "            predictions = torch.argmax(scores, dim =1)\n",
    "            num_correct+= (predictions == y).sum()\n",
    "            num_samples+= predictions.size(0)\n",
    "        accuracy = float(num_correct)/float(num_samples)*100\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.95833333333333\n"
     ]
    }
   ],
   "source": [
    "inp,mod = train_model(0.8,512,0.001,400)\n",
    "accuracy = check_accuracy(inp,mod)    \n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
